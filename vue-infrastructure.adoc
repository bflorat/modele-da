# Vue infrastructure
:sectnumlevels: 4
:toclevels: 4
:sectnums: 4
:toc: left
:icons: font
:toc-title: Sommaire

*DerniÃ¨re modification* : {docdate} 

*Date de la derniÃ¨re revue globale* : _<Faire rÃ©guliÃ¨rement des revues complÃ¨tes de la vue (au moins une fois par an tant que le projet est actif) et mentionner la date ici>_

*Statut du document* :  _<Indiquer ici le statut de la vue, par exemple 'DRAFT', 'FINALISÃ‰',...>_

//ğŸ·{"id": "e3208a9c-8d35-46a1-9399-aacea9817e0a", "labels": ["contexte"]}
## Introduction

La vue infrastructure dÃ©crit le dÃ©ploiement des modules applicatifs dans leur environnement dâ€™exÃ©cution cible et l'ensemble des dispositifs assurant leur bon fonctionnement.

Les autres vues du dossier sont accessibles link:./README.adoc[d'ici].

Le glossaire du projet est disponible link:glossaire.adoc[ici]. Nous ne reprendrons pas ici les termes fonctionnels ou techniques dÃ©jÃ  dÃ©finis.

[TIP]
====
Cette vue est aussi souvent appelÃ© Â«Â vue  techniqueÂ Â» et concerne l'infrastructure : serveurs, rÃ©seaux, systÃ¨mes d'exploitation, bases de donnÃ©es, intergiciels, â€¦ 

Bref, elle porte sur tout ce qui est externe Ã  l'application et nÃ©cessaire Ã  son exÃ©cution.
====

//ğŸ·{"id": "06fd3383-f875-4a44-a1f8-d135f9050038", "labels": ["references"]}
### Documentation de RÃ©fÃ©rence
[TIP]
Mentionner ici les documents d'architecture de rÃ©fÃ©rence (mutualisÃ©s). Ce document ne doit pas reprendre leur contenu sous peine de devenir rapidement obsolÃ¨te et non maintenable.

.RÃ©fÃ©rences documentaires
[cols="1e,2e,5e,4e"]
|====
|NÂ°|Version|Titre/URL du document|DÃ©tail

|1||Regles_sauvegardes.pdf
|RÃ¨gles concernant les sauvegardes

|====

//ğŸ·{"id": "933039be-008f-40c7-a630-a08002b379f1", "labels": ["context","uncertainty"]}
## Non statuÃ©

//ğŸ·{"id": "87385297-c5c3-44f6-b9e8-7599576dda0a", "labels": []}
### Points nÃ©cessitant une Ã©tude complÃ©mentaire
.Points nÃ©cessitant une Ã©tude complÃ©mentaire
[cols="1e,5e,2e,2e,2e"]
|====
|ID|DÃ©tail|Statut|Porteur du sujet | Ã‰chÃ©ance

|EI1
|Le choix technique de la solution dâ€™API Management reste soumise Ã  Ã©tude complÃ©mentaires
|EN_COURS
|Ã‰quipe Archi Technique
|AVANT 2040

|====

//ğŸ·{"id": "30d20b83-e35d-464b-8286-3ff230fb1471", "labels": []}
### HypothÃ¨ses

.HypothÃ¨ses
[cols="1e,5e"]
|====
|ID|DÃ©tail

|HI1
|Nous prenons l'hypothÃ¨se que d'ici Ã  la MEP du projet, PostgreSQL 17 sera validÃ© en interne.
|====

//ğŸ·{"id": "82a207de-bc6f-4a62-a586-96a2b4c9f4dc", "labels": ["detail_level::overview", "constraints"]}
## Contraintes

[TIP]
====
Les contraintes dÃ©finissent les limites applicables aux exigences du projet.

Il est intÃ©ressant de les expliciter pour obtenir des exigences rÃ©alistes. Par exemple, il ne serait pas valide d'exiger une disponibilitÃ© incompatible avec le niveau de sÃ©curitÃ© Tier du datacenter qui l'hÃ©bergera.

====

//ğŸ·{"id": "cc4a17a8-d68b-43cf-8b4e-c64829d950fc", "labels": ["availability"]}
### Contraintes sur la disponibilitÃ©

[TIP]
====
Les Ã©lÃ©ments ici fournis pourront servir de base au SLO (Service Level Objective). IdÃ©alement, ce dossier devrait simplement pointer sur un tel SLO sans plus de prÃ©cision.

Ce chapitre a une vocation pÃ©dagogique car il rappelle la disponibilitÃ© plafond envisageableÂ : la disponibilitÃ© finale de lâ€™application ne pourra Ãªtre quâ€™infÃ©rieure.
====

//ğŸ·{"id": "a18eb613-e522-4bf5-a1fd-742b9d754ce1", "labels": ["niveau_detail::detaillÃ©","supervision"]}
#### MTTD

[TIP]
====
DÃ©tailler les Ã©lÃ©ments permettant d'estimer le temps moyen de dÃ©tection d'incident (Mean Time To Detect).
====
====
Exemple 1 : Le SI est supervisÃ© en 24/7/365.

Exemple 2 : Le service support production est disponible durant les heures de bureau mais une astreinte est mise en place avec alerting par e-mail et SMS en 24/7 du lundi au vendredi.
====

//ğŸ·{"id": "dc11b031-5685-4972-9832-138fa74cd30b", "labels": ["niveau_detail::detaillÃ©","supervision"]}
#### Outils et normes de supervision

[TIP]
====
Fournir ici les outils et normes de supervisions imposÃ©s au niveau du SI et les Ã©ventuelles contraintes liÃ©es.
====
====
Exemple 1 : L'application sera supervisÃ©e avec Zabbix.

Exemple 2 : Les batchs doivent pouvoir se lancer via un endpoint REST.

Exemple 3 : un batch en erreur ne doit pas pouvoir se relancer sans un acquittement humain.
====

//ğŸ·{"id": "6903a99e-8b8e-464b-909c-d40da5a808d1", "labels": ["niveau_detail::detaillÃ©"]}
#### MTTR

[TIP]
====
Fournir les Ã©lÃ©ments permettant d'estimer le temps moyen de rÃ©paration (Mean Time To Repair). A noter qu'il est important de distinguer le MTTD du MTTR. En effet, ce n'est pas parce qu'une panne est dÃ©tectÃ©e que les compÃ©tences ou ressources nÃ©cessaires Ã  sa correction sont disponibles.

PrÃ©ciser les plages de prÃ©sence des exploitants en journÃ©e et les possibilitÃ©s d'astreintes.

Si vous disposez de statistiques ou de post-mortems, mentionnez les durÃ©es effectives moyennes dÃ©jÃ  observÃ©es.

Lister ici les durÃ©es dâ€™intervention des prestataires matÃ©riels, logiciels, Ã©lectricitÃ©, tÃ©lÃ©comâ€¦

Nous subdivisons de faÃ§on indicative cette section en sous-sections "Hardware", "SystÃ¨me et virtualisation", "RÃ©seau", et "Restauration de donnÃ©es". D'autres catÃ©gories sont possibles.
====

//ğŸ·{"id": "e7470aba-8588-4792-bc94-28e4bf186b63", "labels": ["niveau_detail::approfondi"]}
##### MatÃ©riel

TIP: DÃ©crire ici les Ã©lÃ©ments permettant de prÃ©voir le MTTR des Ã©lÃ©ments hardware (serveurs / baies / Ã©quipements rÃ©seau / systÃ¨mes Ã©lectriques, etc.). Lister par exemple ici les durÃ©es dâ€™intervention des prestataires matÃ©riels, Ã©lectricitÃ©â€¦.

====
Exemple 1 : Cinq serveurs physiques de spare sont disponibles Ã  tout moment.

Exemple 2 : Le contrat de support Hitashi prÃ©voit une intervention sur les baies SAN en moins de 24h.

Exemple 3 : le remplacement de support matÃ©riel IBM sur les lames BladeCenter est assurÃ© en 4h de 8h Ã  17h, jours ouvrÃ©s uniquement.
====

//ğŸ·{"id": "96cd73f1-0dca-447e-8fc8-2d9c03399e1c", "labels": ["niveau_detail::approfondi"]}
##### SystÃ¨me et virtualisation

TIP: Lister ici les Ã©lÃ©ments permettant d'estimer le temps de correction d'un problÃ¨me liÃ© Ã  l'OS ou Ã  une Ã©ventuelle solution de virtualisation.

====
Exemple 1 : Au moins un expert de chaque domaine principal (systÃ¨me et virtualisation, stockage, rÃ©seau) est prÃ©sent durant les heures de bureau.

Exemple 2 : Comme toute application hÃ©bergÃ©e au datacenter de la rÃ©gion X, lâ€™application disposera de la prÃ©sence dâ€™exploitants de 7h Ã  20h jours ouvrÃ©s. Aucune astreinte nâ€™est possible.

Exemple 3 : Le temps de restauration observÃ© d'une sauvegarde Veeam de VM de 40 Gio est de 45 mins.

====

//ğŸ·{"id": "22a1f1de-1ab0-4a54-bd0f-64c7c5ab9713", "labels": ["niveau_detail::approfondi"]}
##### RÃ©seau

TIP: Lister ici les Ã©lÃ©ments liÃ©s au rÃ©seau permettant d'estimer les durÃ©es dâ€™intervention des prestataires ou fournisseurs Telecomâ€¦

====
Exemple 1 : un ingÃ©nieur rÃ©seau est d'astreinte chaque week-end.

Exemple 2 : Le SLA d'Orange prÃ©voit un rÃ©tablissement de la connexion Ã  Internet en conditions nominales en moins de 24H.
====

//ğŸ·{"id": "b39586c3-6bbe-417f-ad64-eff53c81d283", "labels": ["niveau_detail::detaillÃ©"]}
##### Restauration de donnÃ©es
TIP: Lister ici les Ã©lÃ©ments permettant d'Ã©valuer la durÃ©e de restauration de donnÃ©es (fichiers / objets / base de donnÃ©es). Les exigences de RTO listÃ©es plus bas devront prendre en compte ce MTTR.

====
Exemple 1 : Le temps de restauration Barman d'une base PostgreSQL est d'environ `x/V + y*T/P` heures avec `x`, la taille de la base en Gio, `V` la vitesse de lecture/Ã©criture (Go/h), `y` le nombre de jours de journaux Ã  rejouer, `T` le temps moyen pour rejouer un 1 jour de WAL et `P` le niveau de parallÃ©lisme de la restauration. 

Exemple 2 : La restauration d'une sauvegarde offline (sur bandes) nÃ©cessite au minimum 4H de prÃ©paration supplÃ©mentaire.
====

//ğŸ·{"id": "421860fb-b6b3-461a-b149-57c6ba6dae41", "labels": ["niveau_detail::approfondi"]}
#### Interruptions programmÃ©es

[TIP]
====
Fournir ici la liste et la durÃ©e des interruptions programmÃ©es standards dans le SI.
====

====
Exemple 1 : On estime l'interruption de chaque serveur Ã  5 mins par mois. Le taux de disponibilitÃ© effectif des serveurs en prenant en compte les interruptions programmÃ©es systÃ¨me est donc de 99.99 %.

Exemple 2Â : suite aux mises Ã  jour de sÃ©curitÃ© de certains packages RPM (kernel, libcâ€¦), les serveurs RHEL sont redÃ©marrÃ©s automatiquement la nuit du mercredi suivant la mise Ã  jour. Ceci entraÃ®nera une indisponibilitÃ© de 5 mins en moyenne 4 fois par an.

====

//ğŸ·{"id": "21d704f6-f740-40f9-986c-36274643a711", "labels": ["niveau_detail::detaillÃ©"]}
#### Niveau de service du datacenter

[TIP]
====
Fournir ici le niveau de sÃ©curitÃ© du datacenter (DC) selon lâ€™Ã©chelle Uptime InstituteÂ (Tier de 1 Ã  4).  

TIP: A noter que les architectures Cloud modernes privilÃ©gient la redondance des DC sur des sites distants plutÃ´t qu'un niveau Tier plus Ã©levÃ© sur un seul site (Ã  condition de pouvoir rÃ©pliquer efficacement des donnÃ©es et d'accepter un dÃ©lais sur la cohÃ©rence immÃ©diate des donnÃ©es, voir le https://fr.wikipedia.org/wiki/Th%C3%A9or%C3%A8me_CAP[thÃ©orÃ¨me CAP]). De faÃ§on simpliste, on peut calculer que la disponibilitÃ© de deux DC actifs en parallÃ¨le est de sept neufs contre quatre neufs pour un DC Tier 4. Un compromis entre les deux modÃ¨les est le dÃ©ploiement dans des zones redondantes d'un mÃªme site au prix d'une plus grande vulnÃ©rabilitÃ© aux catastrophes.

.Niveaux Tier des datacenters (sourceÂ : Wikipedia)
[cols="1,5,2,2,2,2"]
|====
|Niveau Tier|CaractÃ©ristiques|Taux de disponibilitÃ©|IndisponibilitÃ© statistique annuelle| Maintenance Ã  chaud possible ?| TolÃ©rance aux pannes ?

|Tier 1
|Non redondant
|99,671Â %
|28,8 h
|Non
|Non

|Tier 2
|Redondance partielle
|99,749Â %
|22 h
|Non
|Non

|Tier 3
|MaintenabilitÃ©
|99,982Â %
|1,6 h
|Oui
|Non

|Tier 4
|TolÃ©rance aux pannes
|99,995Â %
|24 mins
|Oui
|Oui

|====
====

====
ExempleÂ : Le datacenter de Paris est de niveau Tier III et celui de Toulouse Tier II.
====

//ğŸ·{"id": "7c1d0446-34df-4572-92b0-19baaba54183", "labels": ["detail_level::overview"]}
#### Plafond de disponibilitÃ© (borne supÃ©rieure)

[TIP]
====
Expliquez clairement aux parties prenantes que, mÃªme avec de la HA au niveau applicatif, la **disponibilitÃ© de bout en bout maximale** est plafonnÃ©e par la disponibilitÃ© des dÃ©pendances sous-jacentes (datacenter, rÃ©seau, plateforme).
Ce **plafond de disponibilitÃ©** est le produit de leurs SLA et est toujours
â‰¤ Ã  la dÃ©pendance la moins disponible.

`A_plafond = âˆ(A_SLA de chaque dÃ©pendance en sÃ©rie)  â‰¤  min(A_SLA)`

**Implication :** les cibles SLO **ne doivent pas dÃ©passer** ce plafond. La HA aide Ã 
sâ€™approcher du plafond, pas Ã  le dÃ©passer.

**Notes de pÃ©rimÃ¨tre**

* Si toutes les rÃ©pliques se trouvent dans le **mÃªme domaine de dÃ©faillance** (mÃªme DC/Ã©nergie/accÃ¨s),
  le SLA du DC **fixe effectivement le plafond**.
* Pour **rehausser le plafond**, utilisez des **domaines de dÃ©faillance indÃ©pendants** (p. ex. multi-AZ/rÃ©gion) ;
  pour la redondance en parallÃ¨le : `A_parallel = 1 - âˆ(1 - A_i)` (indÃ©pendance supposÃ©e).
====

====
*Exemple (sÃ©riel, un seul DC) :*  
`<Datacenter 99,9 %> Ã— <RÃ©seau interne 99,95 %> Ã— <Plateforme 99,9 %> â‰ˆ **99,75 %**`

MÃªme si la couche applicative est Â« HA 99,999 % Â», la disponibilitÃ© **de bout en bout**
ne peut pas dÃ©passer ~**99,75 %** sur cette infrastructure.
====


//ğŸ·{"id": "4860fb1c-98e9-4c2c-adfc-09ea8149235d", "labels": ["detail_level::overview"]}
#### Gestion des catastrophes

[TIP]
====

Les catastrophes peuvent Ãªtre classÃ©es en trois catÃ©gories:

* Naturelles (tremblements de terre, inondations, ouragans, canicules, etc. ) ;
* Infrastructurelles (accidentel comme les accidents industriels, incendies, pannes Ã©lectriques majeures, pannes majeures du rÃ©seau / stockage / serveurs, les erreurs critiques d'administrateurs ou intentionnelles: militaire, terroriste, sabotage, etc.) ;
* Cyber (DDOS, virus, Ransomware, etc. ).

**Disaster Recovery (DR)** est l'ensemble des stratÃ©gies et solutions mises en place pour **restaurer un systÃ¨me informatique aprÃ¨s une catastrophe**, minimisant ainsi les pertes de donnÃ©es et le temps d'arrÃªt. DR peut inclure des solutions comme :

* **Cold site** : Centre de secours prÃªt Ã  Ãªtre activÃ© mais sans infrastructure active.
* **Warm site** : Infrastructure prÃ©installÃ©e mais nÃ©cessitant une mise en production manuelle.
* **Hot site** : RÃ©plication en temps rÃ©el avec bascule automatique possible.
* **Disaster Recovery as a Service (DRaaS)** : Solutions cloud de restauration rapide (AWS Elastic Disaster Recovery, Azure Site Recovery, etc.).

PRA (Plan de Reprise d'ActivitÃ©) et PCA (Plan de ContinuitÃ© d'ActivitÃ©) sont des stratÃ©gies spÃ©cifiques de **DR** rÃ©pondant Ã  un risque de catastrophe sur le SI :

* **PRA (Plan de Reprise d'ActivitÃ©)**  
  Permet de **reprendre lâ€™activitÃ© aprÃ¨s une catastrophe** dans un dÃ©lai dÃ©fini (RTO). Il repose sur des **sauvegardes, des restaurations et des infrastructures de secours** comme des **DC secondaires, du stockage rÃ©pliquÃ©** ou des **solutions DRaaS**. L'objectif est d'assurer la reprise, mais avec une **interruption temporaire**.

* **PCA (Plan de ContinuitÃ© d'ActivitÃ©)**  
  Permet d'assurer la **continuitÃ© des activitÃ©s critiques** sans interruption notable. Il nÃ©cessite des **clusters actifs-actifs multi-zonaux, une rÃ©plication synchrone des donnÃ©es et des infrastructures hautement redondantes**. Il est plus coÃ»teux et plus complexe quâ€™un PRA.


Un architecte n'utilise pas les mÃªmes technologies suivant qu'on vise un **PRA ou un PCA** :

* **PRA** â†’ Se concentre sur la **sauvegarde et la restauration** en DC de secours, avec un **RTO dÃ©fini** (ex: **snapshots de VMs avec Veeam, DRaaS, bases en mode rÃ©plication asynchrone**).
* **PCA** â†’ NÃ©cessite des **clusters actifs-actifs multi-zonaux** rÃ©partis sur plusieurs **DC distants** avec synchronisation en temps rÃ©el (ex: **Oracle RAC, Ceph, Kafka MirrorMaker**).

Notes: 

* Pour un PCA, la rÃ©plication synchrone est souvent utilisÃ©e pour garantir un RPO nul, mais certaines architectures (ex: vSphere Metro Storage Cluster avec SRDF asynchrone) permettent un PCA avec une rÃ©plication asynchrone, Ã  condition que le RPO reste dans des limites acceptables (perte de quelques transactions seulement). Cependant, une rÃ©plication sur longue distance peut introduire une latence Ã©levÃ©e, impactant les performances. C'est pourquoi ce type de rÃ©plication synchrone n'est pas envisageable pour entre des DC Ã©loignÃ©s de plus de 50 km environ.
* Un PRA peut  quant-Ã  lui tolÃ©rer une rÃ©plication asynchrone ou des sauvegardes pÃ©riodiques selon les exigences mÃ©tier. 
* Les systÃ¨mes de sauvegarde classiques peuvent suffire pour un PRA avec un RTO adaptÃ©, mais sont gÃ©nÃ©ralement insuffisants pour un PCA, qui requiert une rÃ©plication temps rÃ©el. 
* Dans le cas d'un PRA, il faut prÃ©voir une bascule et une prÃ©paration consÃ©quente du DC de secours alors que dans le cas d'un PCA, tous les DC fonctionnent en parallÃ¨le en mode actif/actif de faÃ§on nominale.
* Les tests de bascule devraient Ãªtre rÃ©alisÃ©s au moins une fois par an pour un PRA, et trimestriellement pour un PCA. Ils doivent inclure des tests unitaires (failover dâ€™une application) et globaux (bascule totale du SI).

Note: La gestion des catastrophes est un sujet complexe. C'est l'un des points forts des Clouds publics (OVH, GCP, Azure, AWS, etc.) que de gÃ©rer une partie de cette complexitÃ© pour vous. Des solutions Cloud spÃ©cifiques existent (Disaster Recovery as a Service (DRaaS)).

DÃ©crire entre autresÂ :

* Les matÃ©riels redondÃ©s dans le second DC, nombre de serveurs de spare, capacitÃ© du DC de secours par rapport au DC nominal.
* Pour un PRA, les dispositifs de restauration (OS, donnÃ©es, applications) prÃ©vues et le RTO.
* Pour un PCA, la latence et dÃ©gradation de performances induite par la rÃ©plication synchrone des donnÃ©es entre DC ou la quantitÃ© de transactions perdues acceptables en cas de rÃ©plication asynchrone.
* PrÃ©senter la politique de failback (rÃ©versibilitÃ©)Â : doit-on rebasculer vers le premier DC? CommentÂ ?
* Comment sont organisÃ©s les tests de bascule Ã  blancÂ ? Avec quelle frÃ©quenceÂ ?
====
====
Exemple de PRA : Pour rappel (voir [doc xyz]), les VM sont rÃ©pliquÃ©es dans le DC de secours via la technologie vSphere Metro Storage Cluster utilisant SRDF en mode asynchrone pour la rÃ©plication inter-baies. En cas de catastrophe, la VM rÃ©pliquÃ©e sur le site de secours est Ã  jour et prÃªte Ã  dÃ©marrer. Le RPO est de ~0 secs et le RTO de 30 mins.

Autre exemple de PRA (PME avec son propre DC Ã  Paris)Â : Stockage de deux serveurs de spare dans les locaux de Lille. Sauvegarde Ã  chaud toutes les quatre heures des donnÃ©es principales de l'entreprise et envoi (avec chiffrement client) sur BackBlaze.com. Le RPO est de 4h, le RTO de 2H.

Exemple de PCA avec Ã©lasticitÃ©: Les applications sâ€™exÃ©cutent sous forme de POD Kubernetes sur au moins trois clusters situÃ©es dans des zones gÃ©ographiquement distantes. Les donnÃ©es MongoDB sont shardÃ©es et synchronisÃ©es entre zones via un systÃ¨me de ReplicatSet. Le systÃ¨me est auto-rÃ©gulÃ© par Kubernetes et tout plantage d'un DC sera compensÃ© en quelques secondes par la crÃ©ation de nouveaux POD dans les deux clusters restants. Ainsi, non seulement les utilisateurs n'auront pas de perte de disponibilitÃ© mais ils ne verront pas non plus leurs performances dÃ©gradÃ©es. 
====

//ğŸ·{"id": "c7c4fce5-c971-4ec8-bef7-006381492aff", "labels": ["detail_level::overview"]}
### HÃ©bergement

* OÃ¹ sera hÃ©bergÃ©e cette applicationÂ ? DC "on premises" ? Cloud interne ? CloudÂ IaaSÂ ? PaaSÂ ? autre ?
* Qui administrera cette applicationÂ ? en interneÂ ? Sous-traitÃ©Â ? Pas dâ€™administration (PaaS) â€¦Â ?
====
Exemple 1: Cette application sera hÃ©bergÃ©e en interne dans le DC de Nantes (seul Ã  assurer la disponibilitÃ© de service exigÃ©e) et il sera administrÃ© par lâ€™Ã©quipe X de Lyon. 
====

====
Exemple 2Â : Ã‰tant donnÃ© le niveau de sÃ©curitÃ© trÃ¨s Ã©levÃ© de lâ€™application, la solution devra Ãªtre exploitÃ©e uniquement en interne par des agents assermentÃ©s. Pour la mÃªme raison, les solutions de cloud sont exclues.
====

====
Exemple 3Â : Ã‰tant donnÃ© le nombre dâ€™appels trÃ¨s important de cette application vers le rÃ©fÃ©rentiel `PERSONNE`, elle sera colocalisÃ©e avec le module `COMPTA-API` dans le VLAN `XYZ`.
====

//ğŸ·{"id": "22a1f1de-1ab0-4a54-bd0f-64c7c5ab9713", "labels": ["niveau_detail::detaillÃ©"]}
### Contraintes rÃ©seau

[TIP]
====
Lister les contraintes liÃ©es au rÃ©seau, en particulier le dÃ©bit maximum thÃ©orique et les dÃ©coupages en zones de sÃ©curitÃ©.
====
====
Exemple 1 : Le LAN dispose d'un dÃ©bit maximal de 10 Gbps.
====
====
Exemple 2 : Les modules applicatifs intranet doivent se trouver dans une zone de confiance inaccessible d'Internet.
====

//ğŸ·{"id": "86a3082e-7069-4120-b86f-f886ef919986", "labels": ["niveau_detail::detaillÃ©"]}
### Contraintes de dÃ©ploiement

[TIP]
====
Lister les contraintes liÃ©es au dÃ©ploiement des applications et services dâ€™infrastructure.
====
====
Exemple 1 : Une VM ne doit hÃ©berger qu'une unique instance PostgreSQL.

Exemple 2 : Les applications Java doivent Ãªtre dÃ©ployÃ©es sous forme de .jar exÃ©cutables et non de .war.

Exemple 3 : Toute application doit Ãªtre publiÃ©e sous forme d'image OCI et dÃ©ployable sur Kubernetes via un ensemble de manifests structurÃ©s au format Kustomize.

====

//ğŸ·{"id": "86a3082e-7069-4120-b86f-f886ef919986", "labels": ["niveau_detail::detaillÃ©"]}
### Contraintes liÃ©es au cycle de vie des composants d'infrastructure

[TIP]
====
Lister les contraintes liÃ©es aux mises Ã  jour et maintenance des composants dâ€™infrastructure (systÃ¨mes d'exploitation, intergiciels, bases de donnÃ©es, etc.).
====

====
Exemple 1 : Toute mise Ã  jour de systÃ¨me d'exploitation doit Ãªtre validÃ©e en environnement de recette avant dÃ©ploiement en production.

Exemple 2 : Les mises Ã  jour des bases de donnÃ©es doivent Ãªtre appliquÃ©es en mode rolling upgrade pour Ã©viter toute interruption de service.

Exemple 3 : Les versions de noyau Linux utilisÃ©es en production doivent Ãªtre exclusivement des versions LTS validÃ©es par lâ€™Ã©quipe infrastructure.

Exemple 4 : Tout correctif de sÃ©curitÃ© critique doit Ãªtre appliquÃ© dans un dÃ©lai de 72 heures suivant sa publication.

Exemple 5 : Les images OCI utilisÃ©es en production doivent Ãªtre mises Ã  jour tous les trimestres avec les derniÃ¨res versions validÃ©es des dÃ©pendances.

Exemple 6 : Un calendrier de mise Ã  jour des composants critiques sera Ã©tabli afin dâ€™Ã©viter les failles de sÃ©curitÃ© et d'assurer la compatibilitÃ© avec les dÃ©pendances.

====

//ğŸ·{"id": "0a25770c-6a02-4fa3-82cc-bf5152d3cba6", "labels": ["niveau_detail::detaillÃ©"]}
### Contraintes liÃ©es aux journaux

[TIP]
====
Lister les contraintes liÃ©es aux journaux
====
====
Exemple 1 : Une application ne doit pas produire plus de 1 Tio de journaux / mois.

Exemple 2 : La durÃ©e de rÃ©tention maximale des journaux est de 3 mois.
====

//ğŸ·{"id": "608d63e6-7299-4976-bf59-52fa1c6ac486", "labels": ["niveau_detail::detaillÃ©"]}
### Contraintes de sauvegardes et restaurations

[TIP]
====
Lister les contraintes liÃ©es aux sauvegardes. 

Une contrainte courante est le respect de la mÃ©thode 3-2-1 :

* Au moins 3 exemplaires des donnÃ©es (la donnÃ©e vivante + 2 copies) ;
* Au moins 2 technologies de stockage diffÃ©rentes pour ces 3 copies (exemple : disques SSD pour les donnÃ©es vivantes et deux sauvegardes sur bandes) ;
* Au moins 1 exemplaire hors-ligne et hors site (exemple : 1 jeu de bandes conservÃ© dans un coffre ignifugÃ© Ã  la banque).

====
====
Exemple 1 : L'espace disque maximal pouvant Ãªtre provisionnÃ© par un projet pour les backups est de 100 Tio sur HDD.

Exemple 2 : La durÃ©e de retentions maximale des sauvegardes est de deux ans.

Exemple 3 : Compter 1 min / Gio pour une restauration NetBackup.
====

//ğŸ·{"id": "22e6cfa3-bc3d-466c-a902-9854540258b7", "labels": ["niveau_detail::detaillÃ©"]}
### CoÃ»ts

[TIP]
====
Lister les limites budgÃ©taires.
====
====
Exemple 1 : les frais de services Cloud AWS ne devront pas dÃ©passer 5 Kâ‚¬/ an pour ce projet.
====

//ğŸ·{"id": "f9ed2469-e3e5-48a1-8b69-4b9c9492c6cb", "labels": ["detail_level::overview", "constraint"]}
## Exigences

[TIP]
====
Contrairement aux contraintes qui fixaient le cadre auquel toute application devait se conformer, les exigences non fonctionnelles sont donnÃ©es par les porteurs du projet (Product Owner, MOA, client, etc.).

PrÃ©voir des interviews pour les recueillir. 

Si certaines exigences ne sont pas rÃ©alistes, le mentionner dans le document des points non statuÃ©s.

Les exigences liÃ©es Ã  la disponibilitÃ© devraient Ãªtre prÃ©cisÃ©es via une Ã©tude de risque (type https://cyber.gouv.fr/la-methode-ebios-risk-manager[EBIOS Risk Manager])

====

//ğŸ·{"id": "332c967b-3729-4a5f-984e-fc2f301b0329", "labels": []}
### Plages de fonctionnement

[TIP]
====
On liste ici les plages de fonctionnement principales (ne pas trop dÃ©tailler, ce nâ€™est pas un plan de production). 

Penser aux utilisateurs situÃ©s dans d'autres fuseaux horaires.

Les informations donnÃ©es ici serviront d'entrants au SLA de lâ€™application.
====

====
.Exemple plages de fonctionnement
[cols="1e,5e,2e"]
|====
|No plage| Heures | DÃ©tail

|1
|De 8H00-19H30 heure de Paris , 5J/7 jours ouvrÃ©s
|Ouverture Intranet aux employÃ©s de mÃ©tropole

|2
|De 21h00 Ã  5h00 heure de Paris
|Plage batch

|3
|24 / 7 / 365
|Ouverture Internet aux usagers

|4
|De 5h30-8h30 heure de Paris, 5J/7 jours ouvrÃ©s
|Ouverture Intranet aux employÃ©s de Nouvelle CalÃ©donie
|====
====

//ğŸ·{"id": "08cb1019-20c4-42ef-9bf2-4adf72936c1c", "labels": ["availability"]}
### Exigences de disponibilitÃ©

[TIP]
====
Nous listons ici les exigences de disponibilitÃ©. Les mesures techniques permettant de les atteindre seront donnÃ©es dans lâ€™architecture technique de la solution. 

Les informations donnÃ©es ici serviront d'entrants au SLA de lâ€™application.

Attention Ã  bien cadrer ces exigences car un porteur de projet a souvent tendance Ã  demander une disponibilitÃ© trÃ¨s Ã©levÃ©e sans toujours se rendre compte des implications. Le coÃ»t et la complexitÃ© de la solution augmente exponentiellement avec le niveau de disponibilitÃ© exigÃ©. 

Lâ€™architecture physique, technique voire logicielle change complÃ¨tement en fonction du besoin de disponibilitÃ© (clusters dâ€™intergiciels ou de bases de donnÃ©es, redondances matÃ©riels coÃ»teuses, architecture asynchrone, caches de session, failover, etc.). 

Ne pas oublier Ã©galement les coÃ»ts dâ€™astreinte trÃ¨s importants si les exigences sont trÃ¨s Ã©levÃ©es. De la pÃ©dagogie et un devis permettent en gÃ©nÃ©ral de modÃ©rer les exigences.

On estime en gÃ©nÃ©ral que la haute disponibilitÃ© (HA) commence Ã  deux neufs (99%), soit environ 90h d'indisponibilitÃ© par an.

DÃ©tailler la disponibilitÃ© demandÃ©e par plage.

La disponibilitÃ© exigÃ©e ici devra Ãªtre en cohÃ©rence avec les <<Contraintes sur la disponibilitÃ©>> du SI.
====

.DurÃ©e dâ€™indisponibilitÃ© maximale admissible par plage
[cols="1e,5e"]
|====
|No Plage| IndisponibilitÃ© maximale

|1 
|24h, maximum 7 fois par an

|2
|4h, 8 fois dans l'annÃ©e

|3
|4h, 8 fois dans l'annÃ©e
|====

//ğŸ·{"id": "afdd573d-d1f8-4958-99c1-e404592396d0", "labels": ["level::advanced","niveau_detail::detaillÃ©"]}
### Modes dÃ©gradÃ©s
[TIP]
====
PrÃ©ciser les modes dÃ©gradÃ©s applicatifs envisagÃ©s.
====

====
Exemple 1 : Le site `monsite.com` devra pouvoir continuer Ã  accepter les commandes en lâ€™absence du service de logistique.
====
====
Exemple 2 : Si le serveur SMTP ne fonctionne plus, les mails seront stockÃ©s en base de donnÃ©es puis soumis Ã  nouveau suite Ã  une opÃ©ration manuelle des exploitants.
====

//ğŸ·{"id": "231768e7-6a9d-429e-b200-2febdd91a0e3", "labels": ["niveau::intermÃ©daire", "niveau_detail::detaillÃ©"]}
### Exigences de robustesse

[TIP]
====
La robustesse du systÃ¨me indique sa capacitÃ© Ã  ne pas produire d'erreurs lors dâ€™Ã©vÃ©nements exceptionnels comme une surcharge ou la panne de l'un de ses composants d'infrastructure.

Cette robustesse s'exprime en valeur absolue par unitÃ© de temps : nombre d'erreurs (techniques) par mois, nombre de messages perdus par anâ€¦

Attention Ã  ne pas Ãªtre trop exigeant sur ce point car une grande robustesse peut impliquer la mise en place de systÃ¨mes Ã  tolÃ©rance de panne complexes, coÃ»teux et pouvant aller Ã  l'encontre des capacitÃ©s de montÃ©e en charge, voire mÃªme de la disponibilitÃ©.
====
====
Exemple 1 : Pas plus de 0.001% de requÃªtes en erreur.
====
====
Exemple 2 : L'utilisateur ne devra pas perdre son panier d'achat mÃªme en cas de panne (attention, ce type d'exigence impacte l'architecture en profondeur, voir la section <<Disponibilite>>).
====
====
Exemple 3 : Le systÃ¨me devra pouvoir tenir une charge trois fois supÃ©rieure Ã  la charge moyenne avec un temps de rÃ©ponse de moins de 10 secondes au 95e centile.
====

//ğŸ·{"id": "f0e94586-876d-46ca-b060-b5dcde468734", "labels": ["niveau::intermÃ©daire"]}
### Exigences de RPO

[TIP]
====
La sauvegarde (ou backup) consiste Ã  recopier les donnÃ©es d'une systÃ¨me sur un support dÃ©diÃ© en vue d'une restauration en cas de perte. Ces donnÃ©es sont nÃ©cessaires au systÃ¨me pour fonctionner.

Fournir ici le Recovery Point Objective (RPO) de lâ€™application (en heures). Il peut Ãªtre utile de restaurer suite Ã  :

* Une perte de donnÃ©es matÃ©rielle (peu probable avec des systÃ¨mes de redondance) ;
* Une fausse manipulation d'un power-user ou d'un administrateur (assez courant) ;
* Un bug applicatif ;
* Une destruction de donnÃ©e volontaire (attaque de type ransomware, etc.).

====
====
Exemple : On ne doit pas pouvoir perdre plus d'une journÃ©e de donnÃ©es applicatives.
====

//ğŸ·{"id": "3e07d851-b2dc-422f-9cba-1b4447a5c956", "labels": ["niveau::intermÃ©daire", "project_size::medium", "project_size::large", "detail_level::overview"]}
### Exigences de RTO

[TIP]
====
Le Recovery Time Objective (en heures) est l'objectif de temps maximal autorisÃ© pour la rÃ©ouverture du service suite Ã  un incident.

Cette exigence doit Ãªtre compatible (infÃ©rieure ou Ã©gale) au MTTR donnÃ© en contrainte plus haut. Il est en effet inutile d'exiger un RTO de 1H si les exploitants on mesurÃ© un MTTR effectif de 2H. Elle doit Ã©galement Ãªtre compatible avec l'exigence de disponibilitÃ©.

Ne prÃ©ciser cette valeur que pour expliciter un objectif de restauration prÃ©cis, sinon, ne pas remplir cette rubrique et faire rÃ©fÃ©rence Ã  la contrainte de MTTR plus haut.
====

====
Exemple : On doit pouvoir restaurer et remettre en ligne les 3 Tio de la base XYZ en 1h maximum.
====

//ğŸ·{"id": "cdb68f23-d2c5-4373-9f7d-e358191f0ebf", "labels": ["niveau::intermÃ©daire","niveau_detail::detaillÃ©"]}
### Exigences de dÃ©ploiements et de mises Ã  jour

//ğŸ·{"id": "663ee84f-7dde-4c6d-acf6-a810ab8fafb4", "labels": []}
#### CotÃ© serveur

[TIP]
====
PrÃ©ciser ici comment lâ€™application devra Ãªtre dÃ©ployÃ©e cotÃ© serveur. 

Par exempleÂ :

* L'installation est-elle manuelle ? scriptÃ©es avec des outils d'IT Automation comme Ansible ou SaltStack ? via des images Docker ?
* Comment sont dÃ©ployÃ©es les unitÃ©s dÃ©ployables (modules ou composants d'infrastructure) ? Sous forme de paquetsÂ ? Utilise-t-on un dÃ©pÃ´t de paquets (type yum ou apt)Â ? Utilise-t-on des conteneurs ?
* Comment sont appliquÃ©es les mises Ã  jourÂ ?
====

//ğŸ·{"id": "fd64ad27-05da-42f0-9491-f790642b5d91", "labels": ["gui"]}
#### CotÃ© client

[TIP]
====
PrÃ©ciser ici comment lâ€™application devra Ãªtre dÃ©ployÃ©e cotÃ© clientÂ :

* Si lâ€™application est volumineuse (beaucoup de JS ou dâ€™images par exemple), risque-t-on un impact sur le rÃ©seauÂ ?
* Une mise en cache de proxy locaux est-elle Ã  prÃ©voirÂ ?
* Des rÃ¨gles de firewall ou QoS sont-elles Ã  prÃ©voirÂ ?

CotÃ© client, pour une application JavaÂ :

* Quel version du JRE est nÃ©cessaire sur les clientsÂ ?

CotÃ© client, pour une application client lourdÂ :

* Quel version de lâ€™OS est supportÃ©eÂ ?
* Si lâ€™OS est Windows, lâ€™installation passe-t-elle par un outil de dÃ©ploiement (Novell ZENWorks par exemple)Â ? lâ€™application vient-elle avec un installeur type NullsoftÂ ? Affecte-t-elle le systÃ¨me (variables dâ€™environnements, base de registreâ€¦) ou est-elle en mode portableÂ (simple zip) ?
* Si lâ€™OS est Linux, lâ€™application doit-elle fournie en tant que paquet ? 
* Comment sont appliquÃ©es les mises Ã  jourÂ ?
====

//ğŸ·{"id": "0bbb4d10-bb6c-4cb0-b227-2e97db99eae1", "labels": ["niveau::intermÃ©daire","niveau_detail::detaillÃ©"]}
#### StratÃ©gie de dÃ©ploiement spÃ©cifiques

[TIP]
====
* PrÃ©voit-on un dÃ©ploiement de type blue/greenÂ ? 
* PrÃ©voit-on un dÃ©ploiement de type canary testing ? si oui, sur quel critÃ¨re ?
* Utilise-t-on des feature flags ? si oui, sur quelles fonctionnalitÃ©s ?
====

====
Exemple: L'application sera dÃ©ployÃ©e sur un mode blue/green, c'est-Ã -dire complÃ¨tement installÃ©e sur un ensemble de machines initialement inaccessibles puis une bascule DNS permettra de pointer vers les machines disposant de la derniÃ¨re version.
====

//ğŸ·{"id": "da0d11fe-0dc9-478e-a984-7a80ea1be482", "labels": ["niveau::intermÃ©daire"]}
### Exigences d'Ã©coconception

[TIP]
====
L'Ã©coconception consiste Ã  limiter l'impact environnemental des logiciels et matÃ©riels utilisÃ©s par lâ€™application. Les exigences dans ce domaine s'expriment gÃ©nÃ©ralement en wattheures ou Ã©quivalent CO2.

A noter que la loi franÃ§aise (voir loi https://ecoresponsable.numerique.gouv.fr/publications/guide-pratique-achats-numeriques-responsables/demarche-numerique-responsable/que-prevoit-la-loi/[du nÂ°2020-105 du 10 fÃ©vrier 2020, ou loi AGEC]) exige de rÃ©duire le gaspillage liÃ© au numÃ©rique, notamment concernant l'obsolescence matÃ©rielle (art. 19). 

Prendre Ã©galement en compte les impressions et courriers.

Selon l'ADEME (estimation 2014), les Ã©missions Ã©quivalent CO2 d'un KWH en France continentale pour le tertiaire est de 50 g/KWH.
====
====
Exemple 1 : Le Power Usage Effectiveness (PUE) du site devra Ãªtre de 1.5 ou moins.
====
====
Exemple 2 : La consommation d'encre et de papier devra Ãªtre rÃ©duite de 10% par rapport Ã  2024.
====

//ğŸ·{"id": "602a7a0a-7f25-4512-b0ab-3b97c8a734e0", "labels": ["detail_level::overview", "solution"]}
## Architecture cible

//ğŸ·{"id": "8088138c-5258-4f3a-a293-0984501bb5db", "labels": ["niveau_detail::detaillÃ©"]}
### Principes

[TIP]
====
Quels sont les grands principes d'infrastructure de notre application ?
====
====
Exemples :

* Les modules applicatifs exposÃ©s Ã  Internet dans une DMZ protÃ©gÃ©e derriÃ¨re un pare-feu puis un reverse-proxy et sur un VLAN isolÃ©. 
* Concernant les interactions entre la DMZ et lâ€™intranet, un pare-feu ne permet les communications que depuis lâ€™intranet vers la DMZ.
* Les clusters actifs/actifs seront exposÃ©s derriÃ¨re un LVS + Keepalived avec direct routing pour le retour.
====

//ğŸ·{"id": "17a46000-c51d-4fb7-868c-7386aef5b523", "labels": ["niveau::intermÃ©daire","availability"]}
### DisponibilitÃ© 
 
[TIP] 
==== 

La disponibilitÃ© mesure le pourcentage de temps pendant lequel un systÃ¨me est utilisable dans des conditions acceptables, c'est-Ã -dire accessible et opÃ©rationnel selon les critÃ¨res dÃ©finis (temps de rÃ©ponse, capacitÃ© de traitement, etc.). Il est exprimÃ© en % (exemple: 99.9% = ~8h45 dâ€™indisponibilitÃ©/an).

Fournir ici les dispositifs permettant d'atteindre les <<Exigences de disponibilitÃ©>>. 

Les mesures permettant dâ€™atteindre la disponibilitÃ© exigÃ©e sont nombreuses et devront Ãªtre choisies par lâ€™architecte en fonction de leur apport et de leur coÃ»t (financier, en complexitÃ©, etc.).  

Les indisponibilitÃ©s peuvent-Ãªtre de deux natures :

* IndisponibilitÃ©s non planifiÃ©es (imprÃ©vues) : pannes matÃ©rielles (serveur, disque, rÃ©seau, etc.), bugs ou crashs logiciels, attaques (DDoS, ransomware, etc.), problÃ¨mes dâ€™infrastructure (coupure Ã©lectrique, incendie), ...
* IndisponibilitÃ©s programmÃ©es (maintenance planifiÃ©e) : mises Ã  jour logicielles (OS, application, base de donnÃ©es), remplacements matÃ©riels, changements dâ€™architecture (migration, refonte), tests de bascule (DRP/PRA, failover test), ...

Les indisponibilitÃ© programmÃ©es sont en gÃ©nÃ©ral prises en compte dans le calcul de la disponibilitÃ© globale (sauf si le SLA prÃ©voit le contraire) puisque le service aux utilisateurs n'est alors pas rendu.

Nous regroupons ici les dispositifs de disponibilitÃ© en cinq grandes catÃ©gories : 

* Dispositifs de *supervision* (technique et applicative) permettant de dÃ©tecter au plus tÃ´t les pannes et donc de limiter le MTTD (temps moyen de dÃ©tection). 

* *Dispositifs organisationnels* :  

** la prÃ©sence humaine (astreintes, heures de support Ã©tenduesâ€¦) qui permet d'amÃ©liorer le MTTR (temps moyen de rÃ©solution) et sans laquelle la supervision est inefficiente ; 

** La qualitÃ© de la gestion des incidents (voir les bonnes pratiques ITIL), par exemple un workflow de rÃ©solution d'incident est-il prÃ©vu ? si oui, quel est sa complexitÃ© ? sa durÃ©e de mise en Å“uvre ? des validations hiÃ©rarchiques (affectant donc le MTTR) sont-elles prÃ©vues ? 

* Dispositifs de *haute disponibilitÃ© (HA)* (clusters, load balancers, failover automatique, etc.) qu'il ne faut pas surestimer si les dispositifs prÃ©cÃ©dents sont insuffisants. 

* Dispositifs de *restauration de donnÃ©es* : La procÃ©dure de restauration est-elle bien dÃ©finie et testÃ©e rÃ©guliÃ¨rement ? Lâ€™isolement des sauvegardes est-il assurÃ© pour Ã©viter toute compromission (ex: ransomware, corruption) ? Le temps de restauration est-il compatible avec le RTO dÃ©fini ? En cas de perte de donnÃ©es causÃ©e par une fausse manipulation ou bug dans le code, il faut alors arrÃªter l'application et dans cette situation, pouvoir restaurer rapidement la derniÃ¨re sauvegarde amÃ©liore grandement le MTTR. 

* Architectures et modÃ¨les de dÃ©ploiement limitant les indisponibilitÃ© programmÃ©es : mise Ã  jour sans coupure (Rolling Update, Blue/Green Deployment), clusters HA avec failover automatique (voir plus bas), maintenance sans coupure via redondance active/active (voir plus bas).
 

==== 
[TIP] 
==== 

*Principes de disponibilitÃ© et de redondance*: 

* La *disponibilitÃ© dâ€™un ensemble de composants d'infrastructure en sÃ©rie* : `D = D1 * D2 * â€¦ * Dn`. Exemple : la disponibilitÃ© dâ€™une application utilisant un serveur Tomcat Ã  98 % et une base Oracle Ã  99 % sera de 97.02 %. 

* La *disponibilitÃ© dâ€™un ensemble de composants d'infrastructure en parallÃ¨le* : `D = 1 â€“ (1-D1) * (1- D2) * ..* (1-Dn)`. Exemple : la disponibilitÃ© de trois serveurs Nginx en cluster dont chacun possÃ¨de une disponibilitÃ© de 98 % est de 99.999 %. 

* Il convient d'Ãªtre cohÃ©rent sur la *disponibilitÃ© de chaque maillon de la chaÃ®ne de liaison* : rien ne sert d'avoir un cluster actif/actif de serveurs d'application JEE si tous ces serveurs attaquent une base de donnÃ©es localisÃ©e sur un unique serveur physique avec disques sans RAID. 

* On dÃ©signe par *Â«spareÂ»* un dispositif (serveur, disque, carte Ã©lectroniqueâ€¦) de rechange qui est dÃ©diÃ© au besoin de disponibilitÃ© mais qui n'est pas activÃ© en dehors des pannes. En fonction du niveau de disponibilitÃ© recherchÃ©, il peut Ãªtre dÃ©diÃ© Ã  lâ€™application ou mutualisÃ© au niveau SI.  

* Les *niveaux de redondance* d'un systÃ¨me (modÃ¨le NMR = N-Modular Redundancy) les plus courants sont les suivants (avec N, le nombre de dispositifs assurant un fonctionnement correct en charge) :  

** *N* : aucune redondance (exemple : si l'alimentation unique d'un serveur tombe, le serveur s'arrÃªte) 

** *N+1* : un composant d'infrastructure de rechange est disponible, on peut supporter la panne d'un matÃ©riel (exemple : on a une alimentation de spare disponible). 

** *N+M*: Un seul spare n'est pas suffisant pour tenir la charge, on prÃ©voit au moins M spares. 

** *2N* : le systÃ¨me est entiÃ¨rement redondÃ© en parallÃ¨le et peut donc supporter la perte de la moitiÃ© des composants d'infrastructure (exemple : on dispose de deux alimentations actives en mÃªme temps dont chacune suffit Ã  alimenter le serveur). Ce systÃ¨me est tolerant aux pannes (FT = fault-tolerant). 

** *2N+1*: En plus d'un systÃ¨me entiÃ¨rement redondÃ©, un systÃ¨me de secours est disponible (pour les opÃ©rations de maintenance par exemple). Elle est courante dans les DC critiques et les architectures cloud multi-zonales (AWS, Azure, GCP).

==== 
[TIP] 
==== 
Quelques mots sur les *rÃ©partiteurs de charge* : 

* Un rÃ©partiteur de charge (Load Balancer = LB) est un composant rÃ©seau ou logiciel qui distribue automatiquement le trafic entrant entre plusieurs serveurs afin dâ€™optimiser la disponibilitÃ©, la performance et la tolÃ©rance aux pannes dâ€™une application ; il peut fonctionner Ã  diffÃ©rents niveaux du modÃ¨le OSI, du niveau 4 (TCP/UDP, ex: LVS, F5 LTM) au niveau 7 (HTTP, ex: HAProxy, Nginx, Traefik).

* Un rÃ©partiteur de charge (Load Balancer = LB) est une *brique indispensable Ã  un cluster actif/actif*. 

* Dans la plupart des clusters Ã  vocation de haute disponibilitÃ©, il faut redonder le rÃ©partiteur de charge pour Ã©viter un SPOF. Une approche classique est un LB actif/passif (ex: Keepalived avec VRRP), mais un mode actif/actif est possible avec des solutions comme ECMP (repartition interne Ã  un DC) ou GSLB (repartition multi-DC). Lâ€™essentiel est dâ€™Ã©viter une centralisation excessive qui recrÃ©erait un SPOF.

* Pour les clusters subissant une trÃ¨s forte charge (ex: LB cloud GCP), une approche consiste Ã  dÃ©ployer les LB en actif/actif avec un Ã©quilibrage cÃ´tÃ© client via Anycast DNS, Weighted DNS Routing ou GSLB. 

* Il est crucial de configurer correctement et Ã  frÃ©quence suffisante les tests de vie (*heathcheck*) des nÅ“uds vers lesquels le rÃ©partiteur distribue la charge car sinon, le rÃ©partiteur va continuer Ã  envoyer des requÃªtes vers des nÅ“uds tombÃ©s ou en surcharge. 

* Certains LB avancÃ©s (ex: option redispatch de HAProxy) permettent de rejouer une requÃªte sur un autre nÅ“ud en cas dâ€™Ã©chec. Cela amÃ©liore la tolÃ©rance aux pannes, mais il faut veiller Ã  ne pas rejouer des requÃªtes non idempotentes (ex: POST). Pour cela, lâ€™utilisation dâ€™identifiants dâ€™idempotence (ex: header HTTP `Idempotency-Key`) peut Ãªtre nÃ©cessaire.

* Lisser la charge entre les nÅ“uds et ne pas forcement se contenter de round robin. Un algorithme simple est le LC (Least Connection) permettant de privilÃ©gier les nÅ“uds les moins chargÃ©s, mais il existe d'autres algorithmes, comme Least Response Time, qui prend aussi en compte la latence. Dans le cloud, il peut Ãªtre pertinent de combiner plusieurs critÃ¨res (charge, latence, gÃ©olocalisation, etc.). Attention nÃ©anmoins Ã  bien les tester et en maÃ®triser les implications pour Ã©viter les catastrophes. 

* Dans le monde Open Source, voir par exemple LVS + Keepalived ou HAProxy + Keepalived. Pour Kubernetes, Traefik et Envoy Proxy sont des alternatives populaires, tandis que NGINX reste une rÃ©fÃ©rence pour des architectures classiques. 

* Il existe aussi des "LB as-a-service" comme Cloudflare Load Balancing pour les services web. 


==== 
[TIP] 
====  

*Clustering*: 

* Un cluster est un *ensemble de nÅ“uds (machines) hÃ©bergeant le mÃªme module applicatif*. 
* En fonction du niveau de disponibilitÃ© recherchÃ©, chaque nÅ“ud peut Ãªtre : 

** *actif* : le nÅ“ud traite les requÃªtes (exemple : un serveur Apache parmi dix et derriÃ¨re un rÃ©partiteur de charge). Temps de failover : nul ; 

** *passif en mode Â«hot standbyÂ»* : le nÅ“ud de secours est installÃ© et dÃ©marrÃ© mais ne traite pas les requÃªtes (exemple: une base MySQL slave qui devient master en cas de panne de ce dernier via l'outil mysqlfailover). MTTR de l'ordre de quelques secondes Ã  quelques dizaines de secondes selon la technologie de failover (ex: Patroni pour PostgreSQL, mysqlfailover pour MySQL, Pacemaker pour un cluster Linux).

** *passif en mode Â«warm standbyÂ»* : le nÅ“ud est dÃ©marrÃ© et l'application est installÃ©e mais n'est pas dÃ©marrÃ©e (exemple : un serveur avec une instance Tomcat Ã©teinte hÃ©bergeant notre application). En cas de panne, notre application est dÃ©marrÃ©e automatiquement. MTTR : de l'ordre de la minute (temps de la dÃ©tection de la panne et d'activation de l'application) ; 

** passif en mode Â«cold standbyÂ» : le nÅ“ud est un simple spare. Pour l'utiliser, il faut installer l'application et la dÃ©marrer. MTTR : de plusieurs dizaines de minutes (si l'application et son environnement sont prÃ©configurÃ©s) Ã  une journÃ©e si une installation complÃ¨te est requise. La virtualisation et les conteneurs (Docker, Kubernetes) peuvent accÃ©lÃ©rer la remise en service si les images sont prÃ©chargÃ©es.

* On peut classer les architectures de clusters actif/actif en deux catÃ©gories :  

** Les *clusters actifs/actifs Ã  couplage faible* dans lesquels un nÅ“ud est totalement indÃ©pendant des autres, soit parce que l'applicatif est stateless (le meilleur cas), soit parce que les donnÃ©es transitoires de contexte (typiquement une session HTTP) sont gÃ©rÃ©es isolÃ©ment par chaque nÅ“ud. Dans le dernier cas, si lâ€™application stocke des donnÃ©es de session en mÃ©moire locale, un rÃ©partiteur de charge devra assurer une affinitÃ© de session ('Sticky Sessions'). En cas de panne dâ€™un nÅ“ud, les utilisateurs affectÃ©s perdront leur session. Pour Ã©viter cela, des solutions de stockage des sessions dans un cache distribuÃ© (ex: Redis, Hazelcast) ou en base de donnÃ©es peuvent Ãªtre mises en place (mais ajoutent de complexitÃ© et doivent Ãªtre elles-mÃªmes redondÃ©es pour ne pas devenir un SPOF).

** Les *clusters actifs/actifs Ã  couplage fort* dans lesquels tous les nÅ“uds partagent les mÃªmes donnÃ©es en mÃ©moire. Dans cette architecture, toute donnÃ©e de contexte doit Ãªtre rÃ©pliquÃ©e dans tous les nÅ“uds (ex : cache distribuÃ© de sessions HTTP rÃ©pliquÃ© avec Redis, JGroups, Infinispan, etc.).  


==== 
[TIP] 
==== 
*Failover (basculement automatique)* :

Le failover  est la capacitÃ© d'un cluster de s'assurer qu'en cas de panne, les requÃªtes ne sont plus envoyÃ©es vers le nÅ“ud dÃ©fectueux mais vers un nÅ“ud opÃ©rationnel. Ce *processus est automatique*. 

Sans failover, c'est au client de dÃ©tecter la panne et de se reconfigurer pour rejouer sa requÃªte vers un nÅ“ud actif. Dans les faits, ceci est rarement praticable et les *clusters disposent presque toujours de capacitÃ©s de failover*. 

Une solution de failover peut Ãªtre dÃ©crite par les attributs suivants : 

* Quelle *stratÃ©gie de failback* (retour Ã  la normale) ? Exemples :
  **  Fail Fast : un nÅ“ud est marquÃ© comme dÃ©fectueux dÃ¨s le premier Ã©chec dÃ©tectÃ©.
  **  Fail Soft : plusieurs Ã©checs consÃ©cutifs sont nÃ©cessaires avant de dÃ©clarer un nÅ“ud en panne.
  **  Retry on Next Node : la requÃªte est renvoyÃ©e Ã  un autre nÅ“ud aprÃ¨s un Ã©chec.
  **  Failover Ã  escalade : le systÃ¨me tente d'abord un nÅ“ud de mÃªme niveau (ex: un autre serveur d'application) avant de remonter Ã  un niveau supÃ©rieur (ex: un cluster dans une autre zone ou rÃ©gion). 

* Quelle *solution de dÃ©tection des pannes* ?  

** les rÃ©partiteurs de charge utilisent des *sondes* (health check) trÃ¨s variÃ©es (requÃªtes fictives, analyse du CPU, des journaux, etc.â€¦) vers les nÅ“uds ;  

** les dÃ©tections de panne des clusters actifs/passifs fonctionnent la plupart du temps par Ã©coute des palpitations (*heartbeat*) du serveur actif par le serveur passif, par exemple via des requÃªtes multicast UDP dans le protocole VRRP utilisÃ© par keepalived. 

* Quel *dÃ©lai de dÃ©tection* de la panne ? ParamÃ©trer un dÃ©lai trop court peut entraÃ®ner des bascules inutiles. Il est recommandÃ© dâ€™utiliser un seuil (ex: 3 Ã©checs consÃ©cutifs) pour Ã©viter les faux positifs. En actif/actif, les nÅ“uds en erreur peuvent Ãªtre retirÃ©s rapidement, tandis quâ€™en actif/passif, la promotion du standby peut nÃ©cessiter plusieurs secondes.

* Quelle *pertinence de la dÃ©tection* ? le serveur en panne est-il *vraiment* en panne ? un mauvais paramÃ©trage ou une microcoupure rÃ©seau ne doit pas provoquer une indisponibilitÃ© totale d'un cluster alors que les nÅ“uds sont sains.  

* Quelle stratÃ©gie de failback ? 

** dans un cluster "N-to-1", on rebasculera (failback) sur le serveur qui Ã©tait tombÃ© en panne une fois rÃ©parÃ© et le serveur basculÃ© redeviendra le serveur de secours ; 

** dans un cluster N-to-N (architecture en voie de dÃ©mocratisation avec les solutions PaaS comme AWS Lambda ou CaaS comme Kubernetes) : la charge est automatiquement redistribuÃ©e entre les nÅ“uds restants, et un autoscaler peut ajouter de nouvelles instances si nÃ©cessaire. 

* *Transparent via Ã  vis de lâ€™appelant* ou pas ? La transparence du failover dÃ©pend de lâ€™architecture. En HTTP, un rÃ©partiteur de charge peut masquer la panne en redirigeant immÃ©diatement les requÃªtes vers un autre nÅ“ud. Dans le cas de bases de donnÃ©es, le client doit souvent gÃ©rer un retry. Les systÃ¨mes Ã©vÃ©nementiels comme Kafka peuvent assurer un failover quasi-transparente.


==== 
[TIP] 
==== 

La *tolÃ©rance de panne* : 

La tolÃ©rance de panne (FT = Fault Tolerance) ne doit pas Ãªtre confondue avec la Haute DisponibilitÃ©. Il s'agit d'une version plus stricte de HA visant une disponibilitÃ© quasi absolue (99.999% ou plus) et une absence de perte de donnÃ©es dans des conditions normales de fonctionnement (WikipÃ©dia: "La tolÃ©rance aux pannes est la propriÃ©tÃ© qui permet Ã  un systÃ¨me de continuer Ã  fonctionner correctement en cas de dÃ©faillance d'un ou de certains de ses composants d'infrastructure"). Seuls les systÃ¨mes critiques (santÃ©, militaires, transport, industrieâ€¦) ont en gÃ©nÃ©ral besoin d'un tel niveau de disponibilitÃ©.

Historiquement, cela signifiait une redondance matÃ©rielle complÃ¨te. Dans un monde de micro-services, cela peut Ã©galement Ãªtre rÃ©alisÃ© au niveau logiciel avec des clusters actifs-actifs. De plus, un vÃ©ritable systÃ¨me de tolÃ©rance aux pannes devrait Ã©viter une dÃ©gradation significative des performances vue par les utilisateurs finaux. 

Par exemple, un lecteur RAID 1 offre une tolÃ©rance aux pannes transparente : en cas de panne, le processus Ã©crit ou lit sans erreur aprÃ¨s le basculement automatique sur le disque sain. Ou encore, un cache distribuÃ© mÃ©moire en cluster peut Ã©viter de perdre une session HTTP. 

Certains systÃ¨mes critiques nÃ©cessitent un niveau Ã©levÃ© de tolÃ©rance de panne, par exemple :

* L'aÃ©ronautique avec les architectures Triple Modular Redundancy (TMR) utilisÃ©es dans les avions de ligne.
* Les bases de donnÃ©es distribuÃ©es comme CockroachDB ou Google Spanner, qui assurent une rÃ©plication multi-rÃ©gion synchrone.
* Les systÃ¨mes de messagerie comme Kafka, qui utilisent un systÃ¨me de rÃ©plication ISR (In-Sync Replicas).
* Les infrastructures financiÃ¨res ultra-basse latence pour les transactions boursiÃ¨res.
 
Pour permettre la tolÃ©rance de panne d'un cluster, il faut obligatoirement *disposer d'un cluster actif/actif avec fort couplage* dans lequel les donnÃ©es de contexte sont rÃ©pliquÃ©es Ã  tout moment. Une autre approche intÃ©ressante est d'Ã©viter autant que possible les donnÃ©es de contexte cÃ´tÃ© serveur en favorisant leur stockage cÃ´tÃ© client (ex: dans le navigateur via localStorage ou les jetons JWT). Cependant, cette solution peut Ãªtre limitÃ©e par des contraintes de sÃ©curitÃ© et de volumÃ©trie. Alternativement, un stockage en base de donnÃ©es ou en cache distribuÃ© peut Ãªtre envisagÃ©, en tenant compte des compromis entre fiabilitÃ©, performance et latence.

Un systÃ¨me tolÃ©rant aux pannes (FT) peut rendre une erreur totalement invisible pour le client si un mÃ©canisme de rejeu automatique, de rÃ©plication synchrone ou de reprise transactionnelle est en place (ex: Oracle RAC, PostgreSQL avec rÃ©plication synchrone, Kafka avec rejeu des messages) ; sinon, une requÃªte en cours peut Ã©chouer et nÃ©cessiter une nouvelle soumission (ex: failover manuel en PostgreSQL, crash dâ€™un serveur Redis non rÃ©pliquÃ©, perte dâ€™une transaction financiÃ¨re en cours), ce qui peut poser un **risque dâ€™incohÃ©rence** si lâ€™opÃ©ration nâ€™est pas **idempotente** (ex: double facturation dâ€™un paiement, duplication dâ€™un message non contrÃ´lÃ© en MQ, insertion partielle en base de donnÃ©es).

Attention Ã  *bien qualifier les exigences* avant de construire une architecture FT car en gÃ©nÃ©ral ces solutions : 

* *Complexifient l'architecture* et la rendent donc moins robuste et plus coÃ»teuse Ã  construire, tester, exploiter. 

* *Peuvent dÃ©grader les performances* : les solutions de disponibilitÃ© et de performance vont en gÃ©nÃ©ral dans le mÃªme sens (par exemple, un cluster de machines stateless va diviser la charge par le nombre de nÅ“uds et dans le mÃªme temps, la disponibilitÃ© augmente), mais quelque fois, disponibilitÃ© et performance peuvent Ãªtre antagonistes : dans le cas d'une architecture stateful, typiquement gÃ©rant les sessions HTTP avec un cache distribuÃ© (type Infinispan rÃ©pliquÃ© en mode synchrone ou un Redis persistant sur le master), toute mise Ã  jour transactionnelle de la session ajoute un surcoÃ»t liÃ© Ã  la mise Ã  jour et la rÃ©plication synchrone des caches, ceci pour assurer le failover. En cas de plantage d'un des nÅ“uds, l'utilisateur conserve sa session Ã  la requÃªte suivante et n'a pas Ã  se reconnecter, mais Ã  quel coÃ»t ?  

* *Peuvent mÃªme dÃ©grader la disponibilitÃ©* si les nÅ“uds sont fortement couplÃ©s. Une mise Ã  jour logicielle peut alors nÃ©cessiter lâ€™arrÃªt de lâ€™ensemble du cluster. Cependant, des stratÃ©gies comme les rolling updates, le blue/green deployment ou l'event sourcing peuvent attÃ©nuer ces contraintes.

* *Peuvent crÃ©er des problÃ¨mes d'intÃ©gritÃ© de donnÃ©es* dans le cas de rejeux automatiques (pour rendre l'erreur invisible au client) de requÃªtes non-idempotentes.

==== 


[TIP] 
==== 

La *Haute DisponibilitÃ© (HA)* : 

Un systÃ¨me est gÃ©nÃ©ralement considÃ©rÃ© comme hautement disponible (HA) Ã  partir de 99.9% de disponibilitÃ© (~8h45 dâ€™indisponibilitÃ©/an).

Un systÃ¨me HA repose gÃ©nÃ©ralement sur :

* Des *mÃ©canismes de redondance* (ex: clustering, rÃ©partition de charge, rÃ©plication).
* Des dispositifs de *failover* pour basculer automatiquement en cas de panne.

La TolÃ©rance de Panne (FT) inclut toujours la Haute DisponibilitÃ© (HA), mais la HA ne garantit pas nÃ©cessairement la FT.

==== 


.Quelques solutions de disponibilitÃ© 

.Quelques solutions de disponibilitÃ©
|====
| Solution | CoÃ»t | ComplexitÃ© de mise en Å“uvre | AmÃ©lioration de la disponibilitÃ©

| Disques en RAID 1
| XX
| X
| XXX

| Disques en RAID 10
| X
| X
| XX

| Redondance des alimentations et autres composants d'infrastructure
| XX
| X
| XX

| Bonding des cartes Ethernet
| XX
| X
| X

| Cluster actif/passif
| XX
| XX
| XX

| Cluster actif/actif (souvent avec LB)
| XXX
| XXX
| XXX

| Serveurs/matÃ©riels de spare
| XX
| X
| XX

| Bonne supervision systÃ¨me
| X
| X
| XX

| Bonne supervision applicative
| XX
| XX
| XX

| SystÃ¨mes de test de vie depuis un site distant
| X
| X
| XX

| Astreintes dÃ©diÃ©es Ã  lâ€™application, 24/7/365
| XXX
| XX
| XXX

| RÃ©plication asynchrone des bases de donnÃ©es (ex: PostgreSQL Streaming)
| XX
| XX
| XX

| RÃ©plication synchrone des bases (ex: Galera, Oracle Data Guard)
| XXX
| XXX
| XXX

| RÃ©plication des donnÃ©es sur baie SAN pour restauration rapide
| XX
| X
| XX

| Auto-scaling et orchestration dynamique (Kubernetes, Serverless)
| XXX
| XXX
| XXX

| Stockage distribuÃ© HA (Ceph, GlusterFS, MinIO)
| XXX
| XXX
| XXX

| CDN avec mise en cache distribuÃ© (Cloudflare, Akamai)
| XX
| XX
| XX
|====

====  
Exemple 1 : Pour atteindre la disponibilitÃ© de 98 % exigÃ©e, les dispositifs de disponibilitÃ© envisagÃ©s sont les suivants :  

* Tous les serveurs en **RAID 10 ou RAID 6** + alimentations redondÃ©es.  
* RÃ©partiteur HAProxy + keepalived actif/passif mutualisÃ© avec les autres applications.  
* Cluster actif/actif de deux serveurs Apache + mod_php.  
* **Serveur MariaDB en rÃ©plication asynchrone** avec un basculement manuel en moins de 2h.  
====  

====  
Exemple 2 : Pour atteindre la disponibilitÃ© de 99.97 % exigÃ©e, les dispositifs de disponibilitÃ© envisagÃ©s sont les suivants (pour rappel, l'application sera hÃ©bergÃ©e dans un DC de niveau Tier 3) :  

* Tous les serveurs en **RAID 1** + alimentations redondÃ©es + interfaces en bonding.  
* RÃ©partiteur HAProxy + keepalived actif/passif dÃ©diÃ© Ã  lâ€™application.  
* Cluster actif/actif de 4 serveurs (redondance **N+N**) Apache + mod_php.  
* Instance Oracle en RAC sur deux machines avec **interconnexion Fibre Channel (FC) dÃ©diÃ©e, latence <1 ms**.  
====  

//ğŸ·{"id": "c23ff676-32e3-4957-8cec-6a7619a33567", "labels": ["niveau_detail::detaillÃ©"]}
### DÃ©ploiement en production

[TIP]
====
Fournir ici le modÃ¨le de dÃ©ploiement des modules et composants d'infrastructure en environnement cible sur les diffÃ©rents intergiciels et nÅ“uds physiques (serveurs). 
Ne reprÃ©senter les Ã©quipements rÃ©seau (pare-feu, switchs, routeurs, etc.) que s'ils aident Ã  la comprÃ©hension. 

On le documentera de prÃ©fÃ©rence avec un diagramme de dÃ©ploiement UML2 ou (mieux) un diagramme de dÃ©ploiement C4.

Pour les clusters, donner le facteur d'instanciation de chaque nÅ“ud.

PrÃ©ciser au besoin les contraintes d'affinitÃ© (deux modules doivent s'exÃ©cuter sur le mÃªme nÅ“ud ou le mÃªme intergiciel) ou d'anti-affinitÃ© (deux modules ne doivent pas s'exÃ©cuter sur le mÃªme nÅ“ud ou dans le mÃªme intergiciel). Exemple : Les bases de donnÃ©es et les serveurs d'application doivent Ãªtre sur des nÅ“uds sÃ©parÃ©s pour Ã©viter la contention CPU et garantir l'isolation des ressources.

Identifier clairement le matÃ©riel dÃ©diÃ© Ã  lâ€™application (et Ã©ventuellement Ã  acheter).
====

====
Exemple :

image::diagrammes/archi-infra.svg[Diagramme de dÃ©ploiement MIEL]
====

//ğŸ·{"id": "28ba010e-1c33-41b9-8061-9596710563bc", "labels": ["niveau_detail::detaillÃ©"]}
### Versions des composants d'infrastructure

[TIP]
====
Lister ici OS, bases de donnÃ©es, MOM, serveurs d'application, etc. Ne dÃ©tailler la version prÃ©cise (le `y` ou le `z` de la version que si cette information est pertinente)

====
.Exemple de composants d'infrastructure
[cols="1e,2e,1e,2e"]
|====
|Composant d'infrastructure|RÃ´le|Version |Environnement technique

|Express.js
|Serveur d'application Node.js
|4.21.x
|Debian 13, OpenJDK 1.8.0_144

|Tomcat
|Container Web pour les IHM 
|10.x.x
|RHEL 9, Sun JDK 1.8.0_144

|Nginx 
|Serveur Web
|1.11.x
|Debian 13

|PHP + php5-fpm
|Pages dynamiques de l'IHM XYZ
|8.3.x
|Windows Server 2025 + IIS

|PostgreSQL
|SGBDR
|17.x
|AlmaLinux 9.x 

|====

//ğŸ·{"id": "3ff53ea7-2e7f-4d71-8848-6819ba23c930", "labels": ["niveau_detail::approfondi"]}
### Matrice des flux techniques

[TIP]
====
Lister ici l'intÃ©gralitÃ© des flux techniques utilisÃ©s par l'application. Les ports dâ€™Ã©coute sont prÃ©cisÃ©s. On dÃ©taille aussi les flux d'exploitation (en protocoles JMX ou SNMP par exemple). 

Dans certaines organisations, cette matrice sera trop dÃ©taillÃ©e pour un dossier d'architecture et sera maintenue dans un document gÃ©rÃ© par les intÃ©grateurs ou les exploitants.

Il n'est pas nÃ©cessaire de faire rÃ©fÃ©rence aux flux applicatifs car les lecteurs ne recherchent pas les mÃªmes informations. Ici, les exploitants ou les intÃ©grateurs recherchent lâ€™exhaustivitÃ© des flux Ã  fin d'installation et de configuration des pare-feu par exemple.

Les types de rÃ©seaux incluent les informations utiles sur le rÃ©seau utilisÃ© afin d'apprÃ©cier les performances (TR, latence) et la sÃ©curitÃ©: LAN, VLAN, Internet, LS, WANâ€¦)

====

.Exemple partiel de matrice de flux techniques
[cols="1e,2e,2e,2e,1e,1e,1e"]
|====
|ID|Source|Destination|Type de rÃ©seau|Protocole|Port d'Ã©coute | Chiffrement ?

|1|lb2|IP multicast 224.0.0.18|LAN|VRRP sur UDP|3222 | Non
|2|lb1|host1, host2|LAN|HTTPS|80 | Oui (TLS)
|3|host3, host4, host5|bdd1|LAN|PG|5432 |Oui (via VPN)
|4|sup1|host[1-6]|LAN|SNMP|199 | Non mais utilisation du VLAN d'admin
|====

//ğŸ·{"id": "93947744-e0ec-4bc3-af30-cc60473b7caf", "labels": ["project_size::medium","project_size::large", "niveau_detail::detaillÃ©"]}
### Environnements

[TIP]
====
Fournir ici une vision gÃ©nÃ©rale des environnements utilisÃ©s par l'application. Les environnements les plus communs sont : dÃ©veloppement, recette, prÃ©-production/benchmarks, production, formation.

Dans les grands systÃ¨mes d'information, il est souvent utile de segmenter les environnements en 'plateformes' (ou 'couloirs') constituÃ©es d'un ensemble de machines isolÃ©es les unes des autres (mÃªme s'ils peuvent partager des ressources communes, selon la politique de l'organisation). Par exemple, un environnement de recette peut Ãªtre constituÃ© des plateformes `UAT1` et `UAT2` permettant Ã  deux testeurs de travailler en isolation.

.Environnements
[cols='1,2,2,2']
|====
|Environnement| RÃ´le| Contenu | Plateforme

|DÃ©veloppement
|DÃ©ploiement continu (CD) pour les dÃ©veloppeurs
|Branche `develop` dÃ©ployÃ©e Ã  chaque commit
|Un seul

|Recette 
|Recette fonctionnelle effectuÃ©e par les testeurs
|Tag dÃ©ployÃ© Ã  la fin de chaque Sprint
|UAT1 et UAT2
|====
====

//ğŸ·{"id": "0bbc320c-6291-4a89-b263-66abf1906ab0", "labels": ["niveau::intermÃ©daire"]}
### Ã‰coconception

[TIP]
====
Lister ici les mesures d'infrastructure permettant de rÃ©pondre aux <<exigences_ecoconception,Exigences d'Ã©coconception>>. 

Les enjeux d'Ã©coconception sont souvent alignÃ©s avec les exigences de **performance** (temps de rÃ©ponse, latence, optimisation des ressources) et de **coÃ»t** (rÃ©duction de la consommation Ã©nergÃ©tique, rationalisation des infrastructures). Lorsquâ€™une solution impacte plusieurs de ces dimensions, il est prÃ©fÃ©rable d'y faire simplement rÃ©fÃ©rence.

Cependant, certaines pratiques sont **spÃ©cifiquement liÃ©es Ã  lâ€™Ã©coconception** et doivent Ãªtre prises en compte dÃ¨s la conception de l'architecture.

====

#### Optimisation Ã©nergÃ©tique et infrastructure
* **Mesure et suivi de la consommation Ã©lectrique** :  
  - Utiliser des sondes dâ€™analyse de la consommation comme http://www.powerapi.org/[PowerAPI] (dÃ©veloppÃ© par l'INRIA et l'universitÃ© Lille 1).  
  - IntÃ©grer des solutions de monitoring Ã©nergÃ©tique dans les systÃ¨mes de supervision (ex : Prometheus avec mÃ©triques spÃ©cifiques).  

* **Gestion des ressources et mutualisation** :  
  - Prioriser l'utilisation de **caches** (opcodes, mÃ©moire, HTTPâ€¦) pour rÃ©duire la charge CPU et les accÃ¨s disque.  
  - **Optimiser lâ€™utilisation des conteneurs** en orchestrant dynamiquement les ressources via Kubernetes ou des solutions similaires, pour adapter la consommation en fonction de la charge rÃ©elle.  

* **EfficacitÃ© des datacenters** :  
  - HÃ©berger ses serveurs dans un **datacenter Ã  haut rendement Ã©nergÃ©tique**. Le PUE (**Power Usage Effectiveness**) est l'indicateur clÃ©.  
  - **Exemples de PUE**: OVHcloud atteint un PUE moyen de 1.29 en 2023 avec des optimisations avancÃ©es (refroidissement liquide) ; Certains datacenters hyperscale comme Google Cloud peuvent atteindre 1.1 grÃ¢ce Ã  lâ€™IA et aux optimisations thermiques.  
  - **Attention :** L'efficacitÃ© Ã©nergÃ©tique ne se limite pas au PUE, il faut aussi considÃ©rer **l'origine de l'Ã©nergie** (renouvelable ou fossile).

#### **Impact Ã©nergÃ©tique global**
* **Ã‰valuer lâ€™impact complet de lâ€™application** :  
  - Lâ€™Ã©nergie consommÃ©e **du cÃ´tÃ© des terminaux client et du rÃ©seau** est souvent bien plus Ã©levÃ©e que celle du serveur.  
  - **Allonger la durÃ©e de vie des Ã©quipements** (terminaux et serveurs) est une approche efficace pour limiter l'empreinte carbone.  

* **Optimisation des dÃ©ploiements** :  
  - RÃ©duire le nombre dâ€™instances actives pendant les pÃ©riodes creuses en scalant dynamiquement.  
  - Prioriser le **serverless computing** lorsque cela est pertinent pour Ã©viter dâ€™allouer des ressources inutilisÃ©es.  

[TIP]
====
Pour Ã©valuer et amÃ©liorer l'empreinte Ã©nergÃ©tique d'un SI, des solutions comme le **Green Software Foundation** proposent des modÃ¨les d'analyse.
====

====  
**Exemple 1** : La mise en place d'un cache **Varnish** devant notre CMS rÃ©duira de **50%** le nombre de constructions de pages dynamiques PHP et permettra **l'Ã©conomie de deux serveurs**.  
====  

====  
**Exemple 2** : L'application sera hÃ©bergÃ©e dans un **datacenter avec un PUE de 1.29**, alimentÃ© Ã  **80 % par de lâ€™Ã©nergie renouvelable**.  
====  

====  
**Exemple 3** : Le **scaling automatique des pods Kubernetes** permettra de **rÃ©duire lâ€™empreinte carbone** en dÃ©sactivant les instances inutiles durant les heures creuses.  
====

//ğŸ·{"id": "46e9c057-75cb-4bc0-9c8d-9af81f737c61", "labels": ["level::advanced", "niveau_detail::detaillÃ©"]}
### RÃ©gulation de la charge

//ğŸ·{"id": "32466600-a3a5-465f-9679-2a244b34321e", "labels": ["level::advanced", "niveau_detail::approfondi"]}
#### Coupe-circuits

[TIP]
====
Dans certains cas, des pics extrÃªmes et imprÃ©visibles sont possibles (effet "Slashdot"). 

Si ce risque est identifiÃ©, prÃ©voir un systÃ¨me de fusible avec dÃ©port de toute ou partie de la charge sur un site Web statique avec message d'erreur par exemple. 

Ce dispositif peut Ã©galement servir en cas dâ€™attaque de type DDOS et permet de gÃ¨rer le problÃ¨me et non de le subir car on assure un bon fonctionnement acceptable aux utilisateurs dÃ©jÃ  connectÃ©s.
====

//ğŸ·{"id": "44f0732c-3b29-4bd5-873f-046fc010f728", "labels": ["level::advanced", "niveau_detail::approfondi"]}
#### QualitÃ© de Service

[TIP]
====
Il est Ã©galement utile de prÃ©voir des systÃ¨mes de rÃ©gulation dynamiques, par exemple :

* **Throttling** : rÃ©gulation du dÃ©bit des requÃªtes (exemple : si un client dÃ©passe **1000 appels par minute**, ses requÃªtes sont mises en attente ou ralenties artificiellement).
* **Rate Limiting** : limitation stricte du nombre d'appels qu'un client peut effectuer sur un endpoint (exemple : chaque client est limitÃ© Ã  **100 appels/minute sur le endpoint E**. Toute requÃªte excÃ©dentaire retourne une **erreur 429 Too Many Requests**).
* **SystÃ¨mes de jetons** : chaque client dispose d'un quota de jetons qui limite ses appels. Ce systÃ¨me permet dâ€™accorder des **prioritÃ©s diffÃ©renciÃ©es** en attribuant plus de jetons Ã  certains clients stratÃ©giques.
====

====
**Exemple 1 :**  
Un **systÃ¨me de jetons** rÃ©gulera l'accÃ¨s Ã  la ressource `DetailArticle` avec un total de **1000 jetons simultanÃ©s**.  
Au-delÃ  de cette limite, les requÃªtes obtiendront une **erreur 429 Too Many Requests** et devront appliquer un rejeu avec **backoff exponentiel**.

.Exemple : RÃ©partition des jetons par type d'opÃ©ration
|====
|OpÃ©ration sur `DetailArticle`|Proportion des jetons

|GET | 80%
|POST | 5%
|PUT | 15%
|====

====

====
**Exemple 2 :**  
Un **Rate Limiting** de **100 requÃªtes par source et par minute** sera mis en place au niveau du reverse proxy.  
Les requÃªtes dÃ©passant ce seuil recevront une **erreur 429 Too Many Requests** et devront Ãªtre replanifiÃ©es par le client.  
====

//ğŸ·{"id": "5fa5ed39-9b6d-4dec-a8c1-1dc1929ff796", "labels": ["niveau::intermÃ©daire","niveau_detail::detaillÃ©"]}
### Gestion des timeouts

[TIP]
====
Tous les appels distribuÃ©s (ex : HTTP(S) vers des API, accÃ¨s Ã  un stockage objet, requÃªtes vers une base de donnÃ©es) doivent Ãªtre **strictement limitÃ©s en temps de connexion et en temps d'exÃ©cution**.  
Sans timeouts appropriÃ©s, des contentions peuvent Ã©merger, entraÃ®nant des **blocages critiques et une saturation des ressources** en cas de ralentissement des systÃ¨mes.  

**Principes clÃ©s :**

* **DÃ©finir des timeouts progressifs** le long de la chaÃ®ne de liaison.  
  - Ex : **10 s sur le reverse proxy**, **8 s sur lâ€™API REST**, **5 s sur la base de donnÃ©es**.  
  - Objectif : Ã©viter quâ€™un service d'infrastructure continue de traiter une requÃªte alors que son module appelant a dÃ©jÃ  abandonnÃ©.  
* **Ã‰viter des valeurs de timeout identiques partout**, ce qui pourrait provoquer des pics dâ€™expiration simultanÃ©s et des effets de cascade indÃ©sirables.  
* **Utiliser un retry intelligent avec un backoff exponentiel** (augmentation progressive du dÃ©lai entre chaque nouvelle tentative).  
* **Ajouter un jitter** au backoff exponentiel pour Ã©viter des pics de charge si plusieurs requÃªtes expirent en mÃªme temps.  

**Jitter :**

- Si plusieurs clients Ã©chouent en mÃªme temps et appliquent un **retry avec un dÃ©lai fixe**, ils risquent de saturer le systÃ¨me.  
- Le jitter consiste Ã  **ajouter une variabilitÃ© alÃ©atoire** au dÃ©lai du backoff exponentiel pour Ã©viter ces pics de charge.  
- Exemple :  
  * **Sans jitter** : Tous les clients refont une requÃªte aprÃ¨s **1s, puis 2s, puis 4sâ€¦** â†’ Risque dâ€™embouteillage.  
  * **Avec jitter** : Les retries sont espacÃ©s de **1.1s, 1.8s, 3.6s, 4.2sâ€¦** â†’ La charge est mieux rÃ©partie.  

====

====
**Exemple de timeouts dÃ©finis sur une architecture type :**

|===
|Module ou Composant d'infrastructure|Timeout de connexion (ms)|Timeout d'exÃ©cution (ms)

|Client Rest JavaScript  | 1000 | 5000
|API Gateway (Reverse Proxy) | 1500 | 4000
|API Rest Node.js  | 1000 | 3500
|Base de donnÃ©es PostgreSQL | 500  | 3000

|===

====

//ğŸ·{"id": "c9a330f1-ffde-44e2-a432-a1e178440333", "labels": []}
### Exploitation

[TIP]
====
Lister ici les grands principes dâ€™exploitation de la solution. 

Les dÃ©tails (contenu des sauvegardes, plan de production, planification des traitements, etc.) seront consignÃ©s dans un Dossier dâ€™EXploitation (DEX) sÃ©parÃ©. 

Si cette application suit les standards de l'organisation, il suffit de se rÃ©fÃ©rer au dossier d'exploitation commun.
====

//ğŸ·{"id": "0a3f0e4e-0458-4528-9513-1f75a4ad8464", "labels": ["niveau::intermÃ©daire", "niveau_detail::detaillÃ©"]}
#### Ordre dâ€™arrÃªt/dÃ©marrage

[TIP]
====
PrÃ©ciser ici lâ€™ordre de dÃ©marrage des machines et modules entre eux ainsi que lâ€™ordre dâ€™arrÃªt. En fonction des situations, on peut faire figurer les modules externes ou non. 

En gÃ©nÃ©ral, le dÃ©marrage suit l'ordre inverse de la chaÃ®ne de liaison, tandis que l'arrÃªt respecte l'ordre de dÃ©pendance des composants.

PrÃ©ciser d'Ã©ventuelles contraintes en cas de dÃ©marrage partiel (exemple : le pool de connexions du serveur dâ€™application retente-t-il la connexion Ã  la base de donnÃ©es si celle-ci n'est pas encore disponible ? Combien de fois ? Ã€ quelle frÃ©quence ?).
====
====
.Exemple d'ordre de dÃ©marrage :

. Base `pg1` sur serveur `bdd1` 
. Base `mq1` sur serveur `bdd1` 
. `services1` sur serveurs `host3`, `host4` et `host5`
. `services2` sur serveurs `host3`, `host4` et `host5`
. `batchs` sur serveurs `host1`, `host2`
. `ihm` sur serveurs `host1`, `host2`

.Exemple d'ordre d'arrÃªt :

1. `ihm` sur serveurs `host1`, `host2`
2. `batchs` sur serveurs `host1`, `host2`
3. `services2` sur serveurs `host3`, `host4` et `host5`
4. `services1` sur serveurs `host3`, `host4` et `host5`
5. Base `mq1` sur serveur `bdd1`
6. Base `pg1` sur serveur `bdd1`
====

//ğŸ·{"id": "314a1ef0-48b4-42a4-a8b6-be49250c5a50", "labels": ["niveau::intermÃ©daire", "niveau_detail::detaillÃ©"]}
#### OpÃ©rations programmÃ©es et suivi

[TIP]
====
DÃ©crire ici lâ€™ensemble des opÃ©rations programmÃ©es et leur suivi, y compris :

* Les jobs et leurs Ã©ventuelles interdÃ©pendances (ordre d'exÃ©cution, contraintes, frÃ©quence).
* Les traitements internes (tÃ¢ches de nettoyage, maintenance) qui remplissent uniquement des rÃ´les techniques (purges, reconstruction d'index, suppression de donnÃ©es temporairesâ€¦).
* Lâ€™ordonnanceur ou planificateur utilisÃ© pour piloter les jobs et consolider le plan de production (exemple : VTOM, JobScheduler, Dollar Universe, Control-M, etc.).
* Les Ã©ventuelles spÃ©cificitÃ©s applicatives :

  - DegrÃ© de parallÃ©lisme des jobs ;
  - Plages de temps obligatoires ;
  - Rejeux en cas d'erreur ;
  - Production de rapports dâ€™exÃ©cution (contenu et format).

Il est Ã©galement crucial de dÃ©finir les mÃ©canismes de supervision ou d'alerte pour dÃ©tecter les Ã©checs des jobs critiques.
====

====
Exemple 1 : Les jobs seront ordonnancÃ©s par l'instance JobScheduler de l'organisation.  

* Ils ne devront jamais tourner les jours fÃ©riÃ©s.  
* Leur exÃ©cution sera bornÃ©e aux pÃ©riodes **23h00 - 06h00**. Toute tÃ¢che planifiÃ©e en dehors de cette plage ne sera pas exÃ©cutÃ©e.  
* On ne lancera pas plus de **cinq instances simultanÃ©es** du job `J1`.  
* Chaque job produira un **rapport d'exÃ©cution dÃ©taillÃ©** contenant le nombre d'Ã©lÃ©ments traitÃ©s, la durÃ©e du traitement et les indicateurs mÃ©tier pertinents.
====

====
Exemple 2 : Le job `traiter-demande` fonctionnera **au fil de l'eau**, exÃ©cutÃ© toutes les **5 minutes** via lâ€™ordonnanceur JobScheduler.
====

====
Exemple 3 : Le traitement interne `ti_index` est une **classe Java** appelant des commandes `VACUUM FULL` en JDBC, exÃ©cutÃ©e via un planificateur Quartz **une fois par mois**.
====

//ğŸ·{"id": "0cf18e71-b20e-4b2b-9377-e104c21c9785", "labels": ["niveau::intermÃ©daire", "niveau_detail::approfondi"]}
#### Mise en maintenance

[TIP]
====
DÃ©tailler les dispositifs et procÃ©dures permettant de mettre l'application offline de faÃ§on explicite pour les utilisateurs.
====

====
Exemple 1 : Nous utiliserons le F5 BigIp LTM pour afficher une page d'indisponibilitÃ©.
====
====
Exemple 2 : Un fichier de verrouillage `maintenance.lock` sera utilisÃ© pour dÃ©sactiver l'accÃ¨s au backend. Un script shell dÃ©clenchera un mode dÃ©gradÃ© affichant une page statique temporaire.
====

//ğŸ·{"id": "fd5b00b0-4b23-4cbc-8117-0dcee74ddd8b", "labels": ["niveau_detail::detaillÃ©"]}
#### Sauvegardes et restaurations

##### PÃ©rimÃ¨tre

[TIP]
====

Quel est le pÃ©rimÃ¨tre de la sauvegarde  ? 

* des images/snapshots systÃ¨mes pour restauration systÃ¨me de serveur ou de VM complets ? 
* des systÃ¨mes de fichiers ou des rÃ©pertoires ?
* des bases de donnÃ©es sous forme de dumps ? 
* les journaux ? les traces ?
====

Exemple de pÃ©rimÃ¨tre : 

* Sauvegarde systÃ¨me des VM ;
* Sauvegarde des bases PostgreSQL ;
* Sauvegardes des documents Ceph.

##### StratÃ©gie de sauvegarde

[TIP]
====
Fournir la politique gÃ©nÃ©rale de sauvegarde. Elle doit rÃ©pondre aux <<Exigences de RPO>>. De mÃªme les dispositifs de restauration doivent Ãªtre compatibles avec les <<Exigences de disponibilitÃ©>>.

* Quels types de sauvegardes sont effectuÃ©s ? Ã€ chaud ? En lecture seule ? Ã€ froid (nÃ©cessitant un arrÃªt de service) ?

* Quelle est la pÃ©riodicitÃ© de chaque type de sauvegarde ? (ne pas trop dÃ©tailler ici, ceci sera dans le DEX)

* Quelle est la stratÃ©gie de sauvegarde ?
** complÃ¨tes ? incrÃ©mentales ? diffÃ©rentielles ? (prendre en compte les exigences en disponibilitÃ©. La restauration d'une sauvegarde incrÃ©mentale sera plus longue qu'une restauration de sauvegarde diffÃ©rentielle, elle-mÃªme plus longue qu'une restauration de sauvegarde complÃ¨te) ;
** quel roulement ? (si les supports de sauvegarde sont Ã©crasÃ©s pÃ©riodiquement).

* Comment se fait le bilan de la sauvegarde ? par courriel ? oÃ¹ sont les journaux ? Sont-ils facilement accessibles ? Contiennent-ils des informations sensibles ?

====

====
Exemple de roulement : jeu de 21 sauvegardes sur un an : 

* 6 sauvegardes journaliÃ¨res incrÃ©mentales ;
* 1 sauvegarde complÃ¨te le dimanche, servant de sauvegarde hebdomadaire ;
* 3 sauvegardes hebdomadaires correspondant aux 3 autres dimanches. Le support du dernier dimanche du mois devient la sauvegarde mensuelle ;
* 11 sauvegardes mensuelles correspondant aux 11 derniers mois.
====

##### Outillage

[TIP]
====
Lister ici les outils utilisÃ©s pour les diffÃ©rents types de sauvegardes.

Quel outillage est mis en Å“uvre ? 

* Simple cron + rsync + tar ? 
* Outil Open Source orientÃ© fichier comme Â«Â backup-managerÂ Â» ? 
* Outil de sauvegarde dÃ©dupliquÃ©e type Restic, Borg, Kopia...)
* Outil orientÃ© imaging de VM comme Veeam ou FSArchiver ? 
* Outil orientÃ© Cloud comme Â«Â DuplicityÂ Â» ou Â«Â ResticÂ Â» ?, etc.
* Outil de sauvegarde spÃ©cifique de base de donnÃ©es (comme MySqlDump, Barman...)

====

====
Exemple 1: Sauvegarde de la base PostgreSQL en streaming avec Barman avec un full chaque nuit.
====
====
Exemple 2: Sauvegarde journaliÃ¨re des documents via Restic avec stockage S3 sur OVH Public Cloud. 
====

##### Traitements sur les sauvegardes

[TIP]
====
Lister ici les opÃ©rations rÃ©alisÃ©es sur les sauvegardes :

* Les donnÃ©es sont-elles dÃ©dupliquÃ©es ? (un mÃªme fichier voire bloc de donnÃ©e identique sur la source n'est stockÃ© qu'une fois dans tout le jeu de sauvegarde). La plupart des solutions modernes utilisent ce principe. Par exemple des outils Open Source comme Restic ou propriÃ©taires comme Veeam utilisent massivement de type de fonctionnement (proche du fonctionnement d'un dÃ©pot Git) pour rÃ©duire drastiquement la taille des sauvegardes et Ã©liminer le besoin de sauvegardes full.

* Les sauvegardes sont-elles chiffrÃ©es ? si oui, chiffrement de la partition toute entiÃ¨re, fichier par fichier, les deux ? Faut-il chiffrer Ã©galement le nom des rÃ©pertoires et fichiers sauvegardÃ©s ? PrÃ©ciser l'algorithme de chiffrement utilisÃ© et comment seront gÃ©rÃ©es les clÃ©s (coffres-forts numÃ©riques, code de secours...).

* Les sauvegardes sont-elles compressÃ©es ? si oui, avec quel algorithme ? (lzw, deflate, lzma?, â€¦), avec quel niveau de compression ? attention Ã  trouver le compromis entre durÃ©e de compression / dÃ©compression et gain de stockage.

* Doit-on proposer des fonctionnalitÃ© de 'Point In Time Recovery' (PITR), pour permettre une restauration Ã  la situation d'un instant prÃ©cis paramÃ©trable ?

* Les sauvegardes sont-elles protÃ©gÃ©es de l'Ã©criture et de l'effacement (anti-ransomware) ? Si oui, de faÃ§on temporaire ou dÃ©finitive ?

* Autres fonctionnalitÃ©s ? (tests d'intÃ©gritÃ©, nettoyage automatique dans l'archive, refactoring des fichiers dans l'archive, ...)
====
====
Exemple 1 : DÃ©duplication des sauvegardes de niveau bloc via Restic.
====
====
Exemple 2 : Chiffrement des sauvegardes en AES-256 via une partition chiffrÃ©e LUKS.
====
====
Exemple 3 : Compression lzma2 de niveau 6.
====
====
Exemple 4 : Les sauvegardes en ligne stockÃ©es dans le stockage objet S3 seront protÃ©gÃ©es des ransomewares grÃ¢ce Ã  S3 Object Lock en mode Compliance.
====
====
Exemple 5 : Activation du PITR sur PostgreSQL via Barman pour permettre une restauration Ã  la seconde prÃ¨s en cas de corruption ou d'erreur humaine.
====

##### ModalitÃ©s de stockage

[TIP]
====

PrÃ©ciser le(s) media de stockage des sauvegardes utilisÃ©(s), son lieu de stockage...

* Le mÃ©dia est-il offline, near-line (accessible via un robot de sauvegarde dans une librairie de cassettes) ou online (accessible en permanence) ? Attention, les sauvegardes online et mÃªme near-line sont vulnÃ©rables aux erreurs humaines et aux ransomwares.

* Quelle technologie de stockage est utilisÃ©e pour les sauvegardes ? (bandes magnÃ©tiques type LTO ou DLT ? disques externes ? cartouches RDX ? cloud de stockage comme Amazon S3 ? support optique ? NAS ? etc.)

* OÃ¹ sont stockÃ©es physiquement les sauvegardes ? (idÃ©alement offline et le plus loin possible du systÃ¨me sauvegardÃ© tout en permettant une restauration dans un temps compatible avec le RTO).

* Quelle est la lÃ©gislation du pays hÃ©bergeant nos sauvegardes ? Est-ce compatible avec les exigences juridiques comme le RGPD ? (voir le Cloud Act amÃ©ricain).

* Qui accÃ¨de physiquement aux sauvegardes et Ã  ses journaux ? Ã  la clÃ© de chiffrement ? (penser aux exigences de confidentialitÃ©).

* Avons nous connaissance de toutes les dÃ©pendances externes pouvant nous ralentir (coffre de banque accessible en journÃ©e uniquement par exemple) ?

* Il est fortement prÃ©conisÃ© : 

** d'utiliser un support distinct des donnÃ©es sources ; 
** de disposer d'au moins deux supports de stockage distincts si les donnÃ©es sont vitales Ã  l'organisation ;
** de faire en sorte que les sauvegardes ne soient pas modifiables par la machine qui a Ã©tÃ© sauvegardÃ©e (par exemple, une sauvegarde sur NAS peut Ãªtre supprimÃ©e par erreur en mÃªme temps que les donnÃ©es sauvegardÃ©es).

* RÃ¨gle des "3-2-1" pour les donnÃ©es importantes : il faut au moins deux copies en plus des donnÃ©es de production, stockÃ©es sur deux supports de technologie diffÃ©rentes et au moins une copie offline sur un site externe sÃ©curisÃ© (exemple: coffre-fort en banque).

====

====
Exemple 1: Pour la PME Boucherie Sanzot, on conservera une sauvegarde hebdomadaire des donnÃ©es de comptabilitÃ© en ligne sur le NAS + une copie offline sur disque externe chiffrÃ© et conservÃ©e dans le coffre d'une voiture. On conservera sur les deux supports 12 sauvegardes mensuelles et une sauvegarde annuelle, ce qui permet de revenir jusqu'Ã  2 ans dans le passÃ©.
====
====
Exemple 2: Pour la sauvegarde des donnÃ©es d'imposition, chaque transaction vers la base de donnÃ©es sera sauvegardÃ©e en barman en utilisant les journaux WAL. Chaque nuit, une sauvegarde full barman de la base sera effectuÃ©e. On conservera 7J + 4 semaines + 12 mois + 1 an sur sauvegarde online (disques durs) et en near-ligne sur librairie de sauvegarde Ã  base de bandes LTO. Les donnÃ©es seront chiffrÃ©es et compressÃ©es. Une copie des sauvegardes hebdomadaires sera conservÃ©e sur des bandes offline stockÃ©es sur un site distant sÃ©curisÃ©.
====

##### Restauration

[TIP]
====
Toujours garder Ã  l'esprit que ce que nous voulons _vraiment_, ce sont des restaurations, pas des sauvegardes. Il est crucial de s'assurer que la restauration sera fonctionnelle :

* Les sauvegardes sont-elles correctes et complÃ¨tes ? 
* Quels tests de restauration sont prÃ©vus ? Ã  quelle frÃ©quence (une fois par an est un minium) ?
* Combien de temps une restauration prendra-t-elle  ? Est-ce compatible avec le RTO ?
* Comment sont gÃ©rÃ©es les erreurs ? (rejeux, timeouts, journaux, alertes, etc.)

* Avons nous suffisamment de ressources hardware pour la restauration dans le temps imparti par le RTO (stockage intermÃ©diaires, CPU et mÃ©moire pour la dÃ©compression/dÃ©chiffrement , etcâ€¦) ?

* Comment se font les tests de restauration ?

  ** Quels jeux de tests ? 
  ** Quel formalisme de bilan / suivi ?
  ** OÃ¹ se trouvent les journaux ? 
  ** Risque-t-on d'Ã©craser par erreur les donnÃ©es de production pendant les tests de restauration ? (si oui, tester sur une autre plateforme)
  ** Les donnÃ©es restaurÃ©es lors du test sont-elles bien chiffrÃ©es (le test de restauration ne doit pas faire courir un risque de perte de confidantialitÃ© massive) ?
  ** ...

====

====
Exemple 1: Un test de restauration des donnÃ©es de production sera effectuÃ©e en prÃ©-production au minimum une fois par an.
====
====
Exemple 2: Les tests de restauration se feront sur un systÃ¨me de fichier chiffrÃ© (LUKS).
====
====
Exemple 3 : Une restauration mensuelle des derniÃ¨res sauvegardes PostgreSQL sera effectuÃ©e sur un environnement de test avec exÃ©cution de requÃªtes de validation des donnÃ©es.
====

//ğŸ·{"id": "74ff1a8d-91b4-4437-bbfd-439e3d4b18b5", "labels": ["niveau::intermÃ©daire","niveau_detail::detaillÃ©"]}
#### Journaux

[TIP]
====
Sans Ãªtre exhaustif sur les fichiers de journaux (Ã  prÃ©voir dans le DEX), prÃ©senter la politique gÃ©nÃ©rale de production et de gestion des journaux (le contenu des journaux est abordÃ© quant Ã  lui dans la vue dÃ©veloppement):

* **Politiques de roulement et rÃ©tention** :
  ** Comment sont gÃ©rÃ©s les fichiers de journaux ? Rotation applicative (`DailyRollingFileAppender` log4j, logback) ou systÃ¨me (`logrotate`) ?
  ** Quelle politique de rÃ©tention est appliquÃ©e ? (ex : durÃ©e de conservation, taille maximale avant suppression)
  ** OÃ¹ sont stockÃ©s les anciens journaux ? (fichiers locaux, stockage objet, archive centralisÃ©e...)

* **Centralisation et exploitation des journaux** :
  ** Une solution de collecte et dâ€™analyse des journaux est-elle mise en place ? (ELK, Loki, Splunkâ€¦)
  ** Un monitoring des logs en temps rÃ©el est-il prÃ©vu ? (alertes sur erreurs critiques)

* **Niveaux de journalisation** :
  ** Quel niveau de journalisation est prÃ©vu par type de module (`WARN`, `INFO`, `DEBUG`â€¦) ?
  ** L'application doit-elle permettre de modifier dynamiquement le niveau de logs en production (ex: via JMX, API) ?

* **SÃ©curitÃ© et conformitÃ©** :
  ** Les logs sont-ils protÃ©gÃ©s contre les injections (`Log Injection`) ?
  ** Une anonymisation ou pseudonymisation des donnÃ©es sensibles est-elle prÃ©vue ? (RGPD)
  ** VÃ©rifier la protection contre la modification ou suppression non autorisÃ©e des logs.
  ** Si les journaux sont accessibles en consultation, quel est le mÃ©canisme d'authentification et d'autorisation ?
====

====
.Exemple 1 : Gestion des journaux applicatifs
Les journaux applicatifs du module `service-miel` seront en production au niveau `INFO`, avec roulement journalier, conservation de deux mois, et stockage dans ELK.
====

====
.Exemple 2 : SÃ©curitÃ© des journaux
Les journaux seront protÃ©gÃ©s contre les injections via la mÃ©thode `StringEscapeUtils.escapeHtml4()` de `org.apache.commons.text`.
====

====
.Exemple 3 : Logs dâ€™accÃ¨s
Les logs dâ€™accÃ¨s seront envoyÃ©s sur un serveur distant en plus dâ€™une conservation locale sur 7 jours maximum.
====

//ğŸ·{"id": "2c3d502d-d67c-417b-88f4-d610e158e930", "labels": ["niveau::intermÃ©daire", "niveau_detail::detaillÃ©","supervision"]}
### Supervision

[TIP]
====
La supervision est un **pilier central de la disponibilitÃ©** en permettant de rÃ©duire drastiquement le **MTTD (Mean Time to Detect, temps moyen de dÃ©tection dâ€™une panne)**.  
Une supervision efficace ne doit pas Ãªtre **uniquement rÃ©active** (alerte en cas de panne) mais aussi **proactive** en dÃ©tectant les signaux faibles avant quâ€™une dÃ©faillance ne survienne.

- **MÃ©triques** : donnÃ©es brutes collectÃ©es (% CPU, taille FS, nombre de requÃªtes, etc.), issues de sondes systÃ¨me, middleware ou applicatives.
- **Indicateurs** : combinaisons de plusieurs mÃ©triques avec des seuils dâ€™alerte (ex : _"alerte critique si l'utilisation CPU du serveur `s1` dÃ©passe 95% pendant plus de 5 minutes"_).
====

//ğŸ·{"id": "f31e9b70-8bf9-41b5-bbb0-c6b3f6de9347", "labels": ["niveau::intermÃ©daire", "niveau_detail::approfondi","supervision"]}
#### Supervision technique

[TIP]
====
Lister ici les **mÃ©triques techniques (infrastructure & middleware)** Ã  superviser :

- **SystÃ¨me** :  
  * Utilisation CPU (%), charge moyenne (`load average`), usage mÃ©moire (%), swap in/out.
  * Occupation disque et file system (% dâ€™utilisation, inodes libres).
  * Utilisation rÃ©seau (latence, dÃ©bit, taux dâ€™erreurs).
  * Nombre de processus actifs et threads.
  * IO wait (temps CPU bloquÃ© en attente dâ€™IO).

- **Middleware & bases de donnÃ©es** :  
  * % de **HEAP utilisÃ©e** sur une JVM.
  * Nombre de **threads actifs** sur une JVM.
  * Utilisation dâ€™un **pool de threads** ou **pool de connexions JDBC**.
  * Temps de rÃ©ponse moyen dâ€™une base de donnÃ©es, nombre de requÃªtes en attente, taux de cache hit.
  * Statistiques de garbage collection (GC).
====
====
**Exemple** : Supervision du **% de CPU en IO wait** et de la **charge moyenne du serveur** (`load average`).
====

//ğŸ·{"id": "be41d5fd-e1a8-4a49-bf80-a81c3db693db", "labels": ["niveau::intermÃ©daire", "niveau_detail::approfondi","supervision"]}
#### Supervision applicative et mÃ©tier

[TIP]
====
Lister ici les mÃ©triques **applicatives** ou **mÃ©tier** :

- **MÃ©triques applicatives** :  
  * Nombre de requÃªtes HTTP reÃ§ues par service.
  * Temps de rÃ©ponse moyen par API REST.
  * Taux dâ€™erreur (5xx) des services.

- **MÃ©triques mÃ©tier** :  
  * Nombre de contrats traitÃ©s dans lâ€™heure.
  * Volume de commandes validÃ©es / rejetÃ©es.
  * Nombre de colis Ã  expÃ©dier en attente.

**Business Activity Monitoring (BAM)** :  
Une couche BAM peut Ãªtre mise en place pour gÃ©nÃ©rer des indicateurs orientÃ©s **processus mÃ©tier** Ã  partir de ces mÃ©triques.
====
====
**Exemple** : Lâ€™API REST de supervision exposera une ressource `Metrique` contenant les **indicateurs mÃ©tier clÃ©s** :  

- **Nombre de colis Ã  expÃ©dier**.  
- **Nombre de prÃ©parateurs actifs**.  
- **Taux dâ€™erreur des transactions**.
====

//ğŸ·{"id": "236fd883-5195-4b81-b5dd-f6c66f9ae3f0", "labels": ["niveau::intermÃ©daire", "niveau_detail::approfondi","supervision"]}
#### Outils de supervision & monitoring

[TIP]
====
Une plateforme de supervision collecte, stocke et analyse les mÃ©triques en temps rÃ©el.  
Les outils Open Source les plus courants sont :

- **Collecte des mÃ©triques** :  
  * **Prometheus** (scraping mÃ©triques en HTTP).
  * **Telegraf** (agent pour collecter CPU, mÃ©moire, rÃ©seau, etc.).
  * **SNMP, JMX** pour monitoring systÃ¨me et JVM.

- **Stockage des mÃ©triques** (bases de donnÃ©es de sÃ©ries temporelles) :  
  * **InfluxDB, Prometheus TSDB, TimescaleDB**.
  * **ElasticSearch** (si besoin de logs en plus des mÃ©triques).

- **Visualisation et alerte** :  
  * **Grafana** (tableaux de bord interactifs).
  * **Zabbix, Netdata, Nagios** (supervision systÃ¨me classique).

Les indicateurs sont ensuite affichÃ©s via **tableaux de bord dynamiques** et des **seuils dâ€™alerte** sont dÃ©finis pour notifier les Ã©quipes.
====
====
**Exemple** :  
La **supervision technique et applicative** reposera sur une stack **Grafana + Prometheus + ElasticSearch**.
====

//ğŸ·{"id": "aa3c7bab-527c-4411-a1f2-583a1d62118f", "labels": ["niveau::intermÃ©daire", "niveau_detail::detaillÃ©","supervision"]}
#### Alerting & notifications

[TIP]
====
DÃ©finir les **conditions de dÃ©clenchement des alertes** et les **canaux de notification** :

- **Types dâ€™alertes** :  
  * **Critique** (urgence) â†’ serveur hors ligne, saturation disque, crash applicatif.
  * **Avertissement** â†’ tendance Ã  la hausse, signaux faibles (ex : mÃ©moire consommÃ©e > 80%).

- **Canaux de notification** :  
  * Alertes **par e-mail** (non-urgent).
  * **Slack, Mattermost, Microsoft Teams** (suivi opÃ©rationnel).
  * **SMS ou PagerDuty** (urgence, astreintes 24/7).

- **RÃ¨gles de dÃ©clenchement** :  
  * RÃ©pÃ©tition sur une pÃ©riode avant alerte (Ã©viter le bruit).
  * **CorrÃ©lation dâ€™Ã©vÃ©nements** pour Ã©viter des faux positifs.
====
====
**Exemple** :  
Une **alerte SMS** sera envoyÃ©e si :  

- **Aucune demande nâ€™a Ã©tÃ© reÃ§ue depuis 4 heures**.  
- **Le nombre dâ€™erreurs 5xx dÃ©passe 10/h** sur un module critique.
====

//ğŸ·{"id": "20dff012-aa85-465f-ba2e-272d7580dd0b", "labels": ["niveau::intermÃ©daire", "niveau_detail::detaillÃ©","supervision"]}
##### Supervision boite noire

[TIP]
====
Il est Ã©galement fortement souhaitable et peu coÃ»teux de prÃ©voir un systÃ¨me de tests de supervision boite-noire (via des scÃ©narios dÃ©roulÃ©s automatiquement). L'idÃ©e est ici de tester un systÃ¨me dans son ensemble et avec une vue end-user la plus externe possible (Ã  l'inverse d'une supervision whitebox pour laquelle on supervise des modules bien prÃ©cis avec un comportement attendu).

En gÃ©nÃ©ral, ces tests sont simples (requÃªtes HTTP depuis un curl cronÃ© par exemple). Ils doivent Ãªtre lancÃ©s depuis un ou plusieurs sites distants pour dÃ©tecter les coupures rÃ©seaux. 

Il est rarement nÃ©cessaire qu'ils effectuent des actions de mise Ã  jour. Si tel est le cas, il faudra Ãªtre en mesure d'identifier dans tous les modules les donnÃ©es issues de ce type de requÃªtes pour ne pas polluer les donnÃ©es mÃ©tier et les systÃ¨mes dÃ©cisionnels.
====
====
Exemple pour un site Internet : des tests de supervision boite noire seront mis en Å“uvre via des requÃªtes HTTP lancÃ©es via Netvigie. En cas de panne, un mail est envoyÃ© aux exploitants.
====

//ğŸ·{"id": "f455e87e-47f0-422a-a80b-0ec65517ad53", "labels": ["level::advanced", "niveau_detail::detaillÃ©","supervision"]}
##### MÃ©trologie

[TIP]
====
Le suivi des performances de l'application en production est essentiel pour :

* Disposer d'un retour factuel sur les performances _in vivo_, permettant d'amÃ©liorer la qualitÃ© des dÃ©cisions pour un Ã©ventuel redimensionnement de la plate-forme matÃ©rielle.
* DÃ©tecter les pannes de maniÃ¨re proactive (exemple : une chute brutale du nombre de requÃªtes).
* RÃ©aliser des analyses statistiques sur lâ€™utilisation des modules pour guider la prise de dÃ©cision (exemple : dÃ©commissionnement d'une application peu utilisÃ©e).

Trois grandes familles de solutions existent :

* **APM (Application Performance Monitoring)** :  
  Ces outils injectent des sondes avec un impact limitÃ© sur l'application, collectent les donnÃ©es et les restituent sous forme de tableaux de bord. Certains reconstruisent mÃªme les chaÃ®nes de liaison complÃ¨tes grÃ¢ce Ã  des identifiants de corrÃ©lation injectÃ©s lors des appels distribuÃ©s.  
  **Exemples** : Oracle Enterprise Manager, Oracle Mission Control, Radware, BMC APM, Dynatrace, Glowroot (Open Source), etc.  
  âš  VÃ©rifier que l'overhead (impact sur les performances) de ces solutions est nÃ©gligeable ou maÃ®trisÃ©.

* **MÃ©trologie maison par journaux** :  
  Une solution simple pour des besoins modestes, utilisant les logs applicatifs pour extraire des mÃ©triques de performance.

* **Sites de requÃªtage externes** :  
  Ces services effectuent des appels pÃ©riodiques vers l'application et gÃ©nÃ¨rent des tableaux de bord. Ils permettent de prendre en compte les temps de transit sur le WAN, ce qui n'est pas possible avec des outils internes. Ã€ utiliser en complÃ©ment de la supervision en boÃ®te noire.

====

====
Exemple :  

* Les performances du site seront supervisÃ©es en continu par Datadog ;
* Des analyses de performances plus poussÃ©es seront mises en Å“uvre par **Glowroot**, selon les besoins.
====

//ğŸ·{"id": "53b2f98c-11d9-4aa0-b762-b8f31db0c30f", "labels": ["niveau::intermÃ©daire"]}
### DÃ©commissionnement

[TIP]
====
Ce chapitre sera complÃ©tÃ© lorsque lâ€™application arrivera en fin de vie et devra Ãªtre supprimÃ©e ou remplacÃ©e. Il dÃ©crit notamment :

- Les **donnÃ©es** Ã  archiver ou, au contraire, Ã  dÃ©truire avec un **haut niveau de confiance**.
- Les **Ã©quipements physiques** Ã  Ã©vacuer, recycler ou dÃ©truire de maniÃ¨re sÃ©curisÃ©e.
- Les **procÃ©dures de dÃ©sinstallation** cÃ´tÃ© serveur et/ou client (il est courant que des modules obsolÃ¨tes restent en exÃ©cution, entraÃ®nant des risques de **performance et de sÃ©curitÃ©**).
- Les **contraintes de sÃ©curitÃ©** associÃ©es au dÃ©commissionnement (c'est une **Ã©tape critique** souvent nÃ©gligÃ©e ; par exemple, des disques durs remplis de **donnÃ©es sensibles** peuvent Ãªtre rÃ©cupÃ©rÃ©s aprÃ¨s un simple don de matÃ©riel).
====

====
Exemple : Les serveurs `X`, `Y` et `Z` seront transmis au service dâ€™action sociale pour don caritatif aprÃ¨s un effacement sÃ©curisÃ© des disques durs via la commande `shred` avec **3 passes**, garantissant une suppression dÃ©finitive des donnÃ©es.
====
